{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Step 1: Load the MNIST dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "n_epochs = 3\n",
    "\n",
    "def loadDataSets():\n",
    "    global mnist_trainset\n",
    "\n",
    "    mnist_trainset = datasets.MNIST(root='./data', train=True,\n",
    "                                download=True,\n",
    "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "    global train_loader\n",
    "    train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "    mnist_testset = datasets.MNIST(root='./data', train=False,\n",
    "                                download=True,\n",
    "                                transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "    global test_loader\n",
    "    test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "loadDataSets()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 2: Plot a subset of the Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='Blues', interpolation='none')\n",
    "  plt.title(\"Label: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 3: Construct Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self, initweights = False, usebias = False, hiddenunits = 128):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1, bias = usebias)\n",
    "\n",
    "        self.conv_2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1, bias = usebias)\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.linear_1 = nn.Linear(7 * 7 * 32, hiddenunits, bias=usebias)\n",
    "        self.linear_2 = nn.Linear(hiddenunits, hiddenunits*2, bias=usebias)\n",
    "        self.linear_3 = nn.Linear(hiddenunits*2, 10, bias=usebias)\n",
    "\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        if initweights:\n",
    "            nn.init.kaiming_normal_(self.conv_1.weight, mode='fan_in', nonlinearity='relu')\n",
    "            nn.init.kaiming_normal_(self.conv_2.weight, mode='fan_in', nonlinearity='relu')\n",
    "            nn.init.kaiming_normal_(self.linear_1.weight, mode='fan_in',nonlinearity='relu')\n",
    "            nn.init.kaiming_normal_(self.linear_2.weight, mode='fan_in', nonlinearity='relu')\n",
    "            nn.init.xavier_normal_(self.linear_3.weight)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.linear_1(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        x = self.linear_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.linear_3(x)\n",
    "\n",
    "        out = self.softmax(x)\n",
    "\n",
    "        return out, x\n",
    "\n",
    "\n",
    "def initializeModel(learning_rate, initweight = False, initbias = False, hiddenunits=128):\n",
    "    global cnn\n",
    "    cnn = CNN(initweight, initbias, hiddenunits)\n",
    "\n",
    "    print(cnn)\n",
    "\n",
    "    global loss_fn\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    global optimizer\n",
    "    optimizer = torch.optim.Adam(params=cnn.parameters(), lr=learning_rate)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 4: Training the Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "log_interval = 10\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
    "# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.\n",
    "def train(num_epochs):\n",
    "    # Define your execution device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"The model will be running on\", device, \"device\")\n",
    "\n",
    "    cnn.to(device)\n",
    "\n",
    "    cnn.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        for itr, (image, label) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            pred = cnn(image)[0]\n",
    "            loss = loss_fn(pred, label)\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if itr % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, itr * len(image), len(train_loader.dataset), 100. * itr / len(train_loader), loss.item()))\n",
    "                train_losses.append(loss.item())\n",
    "                train_counter.append((itr*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "                torch.save(cnn.state_dict(), './data/model.pth')\n",
    "                torch.save(optimizer.state_dict(), './data/optimizer.pth')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 5: Test Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test():\n",
    "  cnn.eval()\n",
    "  totalLoss=0\n",
    "  correct=0\n",
    "  total=0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      networkoutput = cnn(data)[0]\n",
    "\n",
    "      loss= loss_fn(networkoutput,target)\n",
    "      totalLoss+=loss.item()\n",
    "\n",
    "      _, predicted = networkoutput.max(1)\n",
    "      total += target.size(0)\n",
    "      correct += predicted.eq(target).sum().item()\n",
    "\n",
    "  test_loss=totalLoss/len(test_loader)\n",
    "  accu=100.*correct/total\n",
    "\n",
    "  test_losses.append(test_loss)\n",
    "\n",
    "  print('Testing Loss: %.3f | Accuracy: %.3f'%(test_loss,accu))\n",
    "\n",
    "\n",
    "initializeModel(0.001, True, True, 64)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "\n",
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 6: Show Model Performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(train_counter, train_losses, color='green')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Training Loss', 'Testing Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 8: Show prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  output = cnn(example_data)[0]\n",
    "\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='Blues', interpolation='none')\n",
    "  plt.title(\"Prediction: {}\".format(\n",
    "    output.data.max(1, keepdim=True)[1][i].item()))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
