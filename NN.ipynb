{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Step 1: Load the MNIST dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "n_epochs = 3\n",
    "\n",
    "\n",
    "def loadDataSets():\n",
    "    trainingdataset = datasets.MNIST(root='./data', train=True,\n",
    "                                     download=True,\n",
    "                                     transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "    global traindata\n",
    "    traindata = torch.utils.data.DataLoader(trainingdataset, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "    testdataset = datasets.MNIST(root='./data', train=False,\n",
    "                                 download=True,\n",
    "                                 transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "    global testdata\n",
    "    testdata = torch.utils.data.DataLoader(testdataset, batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "\n",
    "loadDataSets()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 2: Plot a subset of the Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 6 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "examples = enumerate(traindata)\n",
    "_, (exampledata, exampletargets) = next(examples)\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(exampledata[i][0], cmap='Blues', interpolation='none')\n",
    "    plt.title(\"Label: {}\".format(exampletargets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 3: Construct Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self, initweights=False, usebias=False, hiddenunits=128):\n",
    "        self.hiddenunits = hiddenunits\n",
    "        self.usebias = usebias\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1,\n",
    "                                bias=self.usebias)\n",
    "\n",
    "        self.conv_2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1,\n",
    "                                bias=self.usebias)\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.linear_1 = nn.Linear(1568, self.hiddenunits, bias=self.usebias)\n",
    "        self.linear_2 = nn.Linear(self.hiddenunits, self.hiddenunits * 2, bias=self.usebias)\n",
    "        self.linear_3 = nn.Linear(self.hiddenunits * 2, 10, bias=self.usebias)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        if initweights:\n",
    "            nn.init.kaiming_normal_(self.conv_1.weight, mode='fan_in', nonlinearity='relu')\n",
    "            nn.init.kaiming_normal_(self.conv_2.weight, mode='fan_in', nonlinearity='relu')\n",
    "            nn.init.kaiming_normal_(self.linear_1.weight, mode='fan_in', nonlinearity='relu')\n",
    "            nn.init.kaiming_normal_(self.linear_2.weight, mode='fan_in', nonlinearity='relu')\n",
    "            nn.init.xavier_normal_(self.linear_3.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.linear_1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.linear_3(x)\n",
    "\n",
    "        return self.softmax(x)\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def initializeModel(learning_rate, initweight=False, initbias=False, hiddenunits=128):\n",
    "    global cnn\n",
    "    cnn = CNN(initweight, initbias, hiddenunits)\n",
    "\n",
    "    print(f\"CNN model: {cnn}\")\n",
    "\n",
    "    global loss_fn\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    global optimizer\n",
    "    optimizer = torch.optim.Adam(params=cnn.parameters(), lr=learning_rate)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 4: Training the Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "log_interval = 10\n",
    "trainlosses = []\n",
    "traincounter = []\n",
    "testlosses = []\n",
    "testcounter = [i * len(traindata.dataset) for i in range(n_epochs + 1)]\n",
    "\n",
    "\n",
    "# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.\n",
    "def train(num_epochs):\n",
    "    # Define your execution device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    cnn.to(device)\n",
    "\n",
    "    cnn.train()\n",
    "    total_train_loss = 0\n",
    "    totaltrainlosses = []\n",
    "    totaltrainaccu = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for itr, (image, label) in enumerate(traindata):\n",
    "            optimizer.zero_grad()\n",
    "            cnnoutput = cnn(image)\n",
    "            loss = loss_fn(cnnoutput, label)\n",
    "\n",
    "\n",
    "            lossitem = loss.item()\n",
    "            total_train_loss += lossitem\n",
    "\n",
    "            predicted = cnnoutput.max(1)[1]\n",
    "            correct += predicted.eq(label).sum().item()\n",
    "            total += label.size(0)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if itr % log_interval == 0:\n",
    "                print('Training Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, itr * len(image),\n",
    "                                                                                  len(traindata.dataset),\n",
    "                                                                                  100. * itr / len(traindata),\n",
    "                                                                                  loss.item()))\n",
    "                trainlosses.append(lossitem)\n",
    "                traincounter.append((itr * 64) + ((epoch - 1) * len(traindata.dataset)))\n",
    "\n",
    "        accu = 100. * correct / total\n",
    "        computedloss = total_train_loss / (itr + 1)\n",
    "        totaltrainaccu.append(accu)\n",
    "        print(f\"Total training loss for epoch : {epoch} loss: {computedloss} accuracy: {accu}\")\n",
    "        totaltrainlosses.append(computedloss)\n",
    "        total_train_loss = 0\n",
    "        accu = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "    aggregateloss = 0\n",
    "    aggregateaccu = 0\n",
    "    for indloss in totaltrainlosses:\n",
    "        aggregateloss += indloss\n",
    "    for taccu in totaltrainaccu:\n",
    "        aggregateaccu += taccu\n",
    "    print(f\"Total training loss across epochs : {num_epochs} loss: {aggregateloss/num_epochs} accuracy: {aggregateaccu/num_epochs}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 5: Hyperparameter Tuning with GridSearchCV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def optimize():\n",
    "    lr = 0.001\n",
    "    epochs = 3\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    net = NeuralNetClassifier(\n",
    "        module=CNN, max_epochs=epochs,\n",
    "        optimizer=torch.optim.Adam,\n",
    "        train_split=None,\n",
    "        criterion=loss_fn,\n",
    "        lr=lr, verbose=0)\n",
    "\n",
    "    params = {\n",
    "        'lr': [0.001, 0.01, 0.005],\n",
    "        'max_epochs': [1, 3, 5],\n",
    "        'module__hiddenunits': [32, 64, 128],\n",
    "        'module__usebias': [False, True],\n",
    "        'module__initweights': [False, True]\n",
    "    }\n",
    "\n",
    "    gs = GridSearchCV(\n",
    "        net, params, refit=False, scoring='accuracy', verbose=1, cv=2, error_score='raise'\n",
    "    )\n",
    "\n",
    "    counter = 0\n",
    "    nobatches = 2\n",
    "\n",
    "    for data in traindata:\n",
    "        counter += 1\n",
    "        image, labels = data\n",
    "        image = image.to(device)\n",
    "        labels = labels.to(device)\n",
    "        gs.fit(image, labels)\n",
    "        if counter == nobatches:\n",
    "            break\n",
    "\n",
    "    print(f\"optimized params: {gs.best_params_}\")\n",
    "    return gs\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 6: Test Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def test():\n",
    "    cnn.eval()\n",
    "    totalloss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in traindata:\n",
    "            cnnoutput = cnn(data)\n",
    "\n",
    "            loss = loss_fn(cnnoutput, target)\n",
    "            lossitem = loss.item()\n",
    "            totalloss += lossitem\n",
    "\n",
    "            predicted = cnnoutput.max(1)[1]\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "    testloss = totalloss / len(traindata)\n",
    "    accu = 100. * correct / total\n",
    "\n",
    "    testlosses.append(testloss)\n",
    "\n",
    "    print('Testing Loss: %.3f | Accuracy: %.3f' % (testloss, accu))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step7: Optimize with GridSearchCV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 108 candidates, totalling 216 fits\n",
      "Fitting 2 folds for each of 108 candidates, totalling 216 fits\n",
      "optimized params: {'lr': 0.001, 'max_epochs': 1, 'module__hiddenunits': 128, 'module__initweights': True, 'module__usebias': False}\n",
      "Initializing Neural Network with GridSearchCV Params...\n",
      "lr: 0.001, initweights: True, usebias: False, hiddenunits: 128\n",
      "CNN model: CNN(\n",
      "  (conv_1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (conv_2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (max_pool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear_1): Linear(in_features=1568, out_features=128, bias=False)\n",
      "  (linear_2): Linear(in_features=128, out_features=256, bias=False)\n",
      "  (linear_3): Linear(in_features=256, out_features=10, bias=False)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Testing Loss: 2.311 | Accuracy: 9.872\n",
      "Training Epoch: 0 [0/60000 (0%)]\tLoss: 2.298933\n",
      "Training Epoch: 0 [640/60000 (1%)]\tLoss: 2.309667\n",
      "Training Epoch: 0 [1280/60000 (2%)]\tLoss: 2.305622\n",
      "Training Epoch: 0 [1920/60000 (3%)]\tLoss: 2.294933\n",
      "Training Epoch: 0 [2560/60000 (4%)]\tLoss: 2.311551\n",
      "Training Epoch: 0 [3200/60000 (5%)]\tLoss: 2.308419\n",
      "Training Epoch: 0 [3840/60000 (6%)]\tLoss: 2.299296\n",
      "Training Epoch: 0 [4480/60000 (7%)]\tLoss: 2.296001\n",
      "Training Epoch: 0 [5120/60000 (9%)]\tLoss: 2.301232\n",
      "Training Epoch: 0 [5760/60000 (10%)]\tLoss: 2.288557\n",
      "Training Epoch: 0 [6400/60000 (11%)]\tLoss: 2.289445\n",
      "Training Epoch: 0 [7040/60000 (12%)]\tLoss: 2.296196\n",
      "Training Epoch: 0 [7680/60000 (13%)]\tLoss: 2.266846\n",
      "Training Epoch: 0 [8320/60000 (14%)]\tLoss: 2.221457\n",
      "Training Epoch: 0 [8960/60000 (15%)]\tLoss: 2.157439\n",
      "Training Epoch: 0 [9600/60000 (16%)]\tLoss: 2.084589\n",
      "Training Epoch: 0 [10240/60000 (17%)]\tLoss: 2.115392\n",
      "Training Epoch: 0 [10880/60000 (18%)]\tLoss: 2.072630\n",
      "Training Epoch: 0 [11520/60000 (19%)]\tLoss: 2.140623\n",
      "Training Epoch: 0 [12160/60000 (20%)]\tLoss: 2.022421\n",
      "Training Epoch: 0 [12800/60000 (21%)]\tLoss: 1.961417\n",
      "Training Epoch: 0 [13440/60000 (22%)]\tLoss: 2.002858\n",
      "Training Epoch: 0 [14080/60000 (23%)]\tLoss: 2.011863\n",
      "Training Epoch: 0 [14720/60000 (25%)]\tLoss: 1.917283\n",
      "Training Epoch: 0 [15360/60000 (26%)]\tLoss: 1.941492\n",
      "Training Epoch: 0 [16000/60000 (27%)]\tLoss: 1.920529\n",
      "Training Epoch: 0 [16640/60000 (28%)]\tLoss: 1.928852\n",
      "Training Epoch: 0 [17280/60000 (29%)]\tLoss: 1.862126\n",
      "Training Epoch: 0 [17920/60000 (30%)]\tLoss: 1.979204\n",
      "Training Epoch: 0 [18560/60000 (31%)]\tLoss: 1.825363\n",
      "Training Epoch: 0 [19200/60000 (32%)]\tLoss: 1.739256\n",
      "Training Epoch: 0 [19840/60000 (33%)]\tLoss: 1.790268\n",
      "Training Epoch: 0 [20480/60000 (34%)]\tLoss: 1.828504\n",
      "Training Epoch: 0 [21120/60000 (35%)]\tLoss: 1.720189\n",
      "Training Epoch: 0 [21760/60000 (36%)]\tLoss: 1.793130\n",
      "Training Epoch: 0 [22400/60000 (37%)]\tLoss: 1.799505\n",
      "Training Epoch: 0 [23040/60000 (38%)]\tLoss: 1.705594\n",
      "Training Epoch: 0 [23680/60000 (39%)]\tLoss: 1.689963\n",
      "Training Epoch: 0 [24320/60000 (41%)]\tLoss: 1.722928\n",
      "Training Epoch: 0 [24960/60000 (42%)]\tLoss: 1.625746\n",
      "Training Epoch: 0 [25600/60000 (43%)]\tLoss: 1.698314\n",
      "Training Epoch: 0 [26240/60000 (44%)]\tLoss: 1.659128\n",
      "Training Epoch: 0 [26880/60000 (45%)]\tLoss: 1.709351\n",
      "Training Epoch: 0 [27520/60000 (46%)]\tLoss: 1.642843\n",
      "Training Epoch: 0 [28160/60000 (47%)]\tLoss: 1.651336\n",
      "Training Epoch: 0 [28800/60000 (48%)]\tLoss: 1.738686\n",
      "Training Epoch: 0 [29440/60000 (49%)]\tLoss: 1.653543\n",
      "Training Epoch: 0 [30080/60000 (50%)]\tLoss: 1.703783\n",
      "Training Epoch: 0 [30720/60000 (51%)]\tLoss: 1.674318\n",
      "Training Epoch: 0 [31360/60000 (52%)]\tLoss: 1.744926\n",
      "Training Epoch: 0 [32000/60000 (53%)]\tLoss: 1.763924\n",
      "Training Epoch: 0 [32640/60000 (54%)]\tLoss: 1.676071\n",
      "Training Epoch: 0 [33280/60000 (55%)]\tLoss: 1.589820\n",
      "Training Epoch: 0 [33920/60000 (57%)]\tLoss: 1.594486\n",
      "Training Epoch: 0 [34560/60000 (58%)]\tLoss: 1.638870\n",
      "Training Epoch: 0 [35200/60000 (59%)]\tLoss: 1.649962\n",
      "Training Epoch: 0 [35840/60000 (60%)]\tLoss: 1.678362\n",
      "Training Epoch: 0 [36480/60000 (61%)]\tLoss: 1.607742\n",
      "Training Epoch: 0 [37120/60000 (62%)]\tLoss: 1.612972\n",
      "Training Epoch: 0 [37760/60000 (63%)]\tLoss: 1.690375\n",
      "Training Epoch: 0 [38400/60000 (64%)]\tLoss: 1.715055\n",
      "Training Epoch: 0 [39040/60000 (65%)]\tLoss: 1.625747\n",
      "Training Epoch: 0 [39680/60000 (66%)]\tLoss: 1.614323\n",
      "Training Epoch: 0 [40320/60000 (67%)]\tLoss: 1.650292\n",
      "Training Epoch: 0 [40960/60000 (68%)]\tLoss: 1.645865\n",
      "Training Epoch: 0 [41600/60000 (69%)]\tLoss: 1.654074\n",
      "Training Epoch: 0 [42240/60000 (70%)]\tLoss: 1.688321\n",
      "Training Epoch: 0 [42880/60000 (71%)]\tLoss: 1.716736\n",
      "Training Epoch: 0 [43520/60000 (72%)]\tLoss: 1.657239\n",
      "Training Epoch: 0 [44160/60000 (74%)]\tLoss: 1.577665\n",
      "Training Epoch: 0 [44800/60000 (75%)]\tLoss: 1.646103\n",
      "Training Epoch: 0 [45440/60000 (76%)]\tLoss: 1.648456\n",
      "Training Epoch: 0 [46080/60000 (77%)]\tLoss: 1.642086\n",
      "Training Epoch: 0 [46720/60000 (78%)]\tLoss: 1.589251\n",
      "Training Epoch: 0 [47360/60000 (79%)]\tLoss: 1.575733\n",
      "Training Epoch: 0 [48000/60000 (80%)]\tLoss: 1.625367\n",
      "Training Epoch: 0 [48640/60000 (81%)]\tLoss: 1.608551\n",
      "Training Epoch: 0 [49280/60000 (82%)]\tLoss: 1.592981\n",
      "Training Epoch: 0 [49920/60000 (83%)]\tLoss: 1.524945\n",
      "Training Epoch: 0 [50560/60000 (84%)]\tLoss: 1.618249\n",
      "Training Epoch: 0 [51200/60000 (85%)]\tLoss: 1.623887\n",
      "Training Epoch: 0 [51840/60000 (86%)]\tLoss: 1.604558\n",
      "Training Epoch: 0 [52480/60000 (87%)]\tLoss: 1.534546\n",
      "Training Epoch: 0 [53120/60000 (88%)]\tLoss: 1.566920\n",
      "Training Epoch: 0 [53760/60000 (90%)]\tLoss: 1.534785\n",
      "Training Epoch: 0 [54400/60000 (91%)]\tLoss: 1.579509\n",
      "Training Epoch: 0 [55040/60000 (92%)]\tLoss: 1.564008\n",
      "Training Epoch: 0 [55680/60000 (93%)]\tLoss: 1.536832\n",
      "Training Epoch: 0 [56320/60000 (94%)]\tLoss: 1.573064\n",
      "Training Epoch: 0 [56960/60000 (95%)]\tLoss: 1.526912\n",
      "Training Epoch: 0 [57600/60000 (96%)]\tLoss: 1.518287\n",
      "Training Epoch: 0 [58240/60000 (97%)]\tLoss: 1.515926\n",
      "Training Epoch: 0 [58880/60000 (98%)]\tLoss: 1.567877\n",
      "Training Epoch: 0 [59520/60000 (99%)]\tLoss: 1.509205\n",
      "Total training loss for epoch : 0 loss: 1.8002544788917754 accuracy: 67.49333333333334\n",
      "Total training loss across epochs : 1 loss: 1.8002544788917754 accuracy: 67.49333333333334\n",
      "Testing Loss: 1.545 | Accuracy: 92.933\n",
      "Training Epoch: 0 [0/60000 (0%)]\tLoss: 1.556781\n",
      "Training Epoch: 0 [640/60000 (1%)]\tLoss: 1.554022\n",
      "Training Epoch: 0 [1280/60000 (2%)]\tLoss: 1.564238\n",
      "Training Epoch: 0 [1920/60000 (3%)]\tLoss: 1.569509\n",
      "Training Epoch: 0 [2560/60000 (4%)]\tLoss: 1.536240\n",
      "Training Epoch: 0 [3200/60000 (5%)]\tLoss: 1.632142\n",
      "Training Epoch: 0 [3840/60000 (6%)]\tLoss: 1.565000\n",
      "Training Epoch: 0 [4480/60000 (7%)]\tLoss: 1.542898\n",
      "Training Epoch: 0 [5120/60000 (9%)]\tLoss: 1.562137\n",
      "Training Epoch: 0 [5760/60000 (10%)]\tLoss: 1.537532\n",
      "Training Epoch: 0 [6400/60000 (11%)]\tLoss: 1.502498\n",
      "Training Epoch: 0 [7040/60000 (12%)]\tLoss: 1.509711\n",
      "Training Epoch: 0 [7680/60000 (13%)]\tLoss: 1.568911\n",
      "Training Epoch: 0 [8320/60000 (14%)]\tLoss: 1.559260\n",
      "Training Epoch: 0 [8960/60000 (15%)]\tLoss: 1.491377\n",
      "Training Epoch: 0 [9600/60000 (16%)]\tLoss: 1.540888\n",
      "Training Epoch: 0 [10240/60000 (17%)]\tLoss: 1.525166\n",
      "Training Epoch: 0 [10880/60000 (18%)]\tLoss: 1.518103\n",
      "Training Epoch: 0 [11520/60000 (19%)]\tLoss: 1.520674\n",
      "Training Epoch: 0 [12160/60000 (20%)]\tLoss: 1.540225\n",
      "Training Epoch: 0 [12800/60000 (21%)]\tLoss: 1.583530\n",
      "Training Epoch: 0 [13440/60000 (22%)]\tLoss: 1.551628\n",
      "Training Epoch: 0 [14080/60000 (23%)]\tLoss: 1.494418\n",
      "Training Epoch: 0 [14720/60000 (25%)]\tLoss: 1.528692\n",
      "Training Epoch: 0 [15360/60000 (26%)]\tLoss: 1.566056\n",
      "Training Epoch: 0 [16000/60000 (27%)]\tLoss: 1.505061\n",
      "Training Epoch: 0 [16640/60000 (28%)]\tLoss: 1.510454\n",
      "Training Epoch: 0 [17280/60000 (29%)]\tLoss: 1.544169\n",
      "Training Epoch: 0 [17920/60000 (30%)]\tLoss: 1.504397\n",
      "Training Epoch: 0 [18560/60000 (31%)]\tLoss: 1.547153\n",
      "Training Epoch: 0 [19200/60000 (32%)]\tLoss: 1.500883\n",
      "Training Epoch: 0 [19840/60000 (33%)]\tLoss: 1.536467\n",
      "Training Epoch: 0 [20480/60000 (34%)]\tLoss: 1.535721\n",
      "Training Epoch: 0 [21120/60000 (35%)]\tLoss: 1.535754\n",
      "Training Epoch: 0 [21760/60000 (36%)]\tLoss: 1.518707\n",
      "Training Epoch: 0 [22400/60000 (37%)]\tLoss: 1.505949\n",
      "Training Epoch: 0 [23040/60000 (38%)]\tLoss: 1.491374\n",
      "Training Epoch: 0 [23680/60000 (39%)]\tLoss: 1.509790\n",
      "Training Epoch: 0 [24320/60000 (41%)]\tLoss: 1.532314\n",
      "Training Epoch: 0 [24960/60000 (42%)]\tLoss: 1.497292\n",
      "Training Epoch: 0 [25600/60000 (43%)]\tLoss: 1.511622\n",
      "Training Epoch: 0 [26240/60000 (44%)]\tLoss: 1.545701\n",
      "Training Epoch: 0 [26880/60000 (45%)]\tLoss: 1.564562\n",
      "Training Epoch: 0 [27520/60000 (46%)]\tLoss: 1.532114\n",
      "Training Epoch: 0 [28160/60000 (47%)]\tLoss: 1.512194\n",
      "Training Epoch: 0 [28800/60000 (48%)]\tLoss: 1.585319\n",
      "Training Epoch: 0 [29440/60000 (49%)]\tLoss: 1.541721\n",
      "Training Epoch: 0 [30080/60000 (50%)]\tLoss: 1.525773\n",
      "Training Epoch: 0 [30720/60000 (51%)]\tLoss: 1.514664\n",
      "Training Epoch: 0 [31360/60000 (52%)]\tLoss: 1.567211\n",
      "Training Epoch: 0 [32000/60000 (53%)]\tLoss: 1.512982\n",
      "Training Epoch: 0 [32640/60000 (54%)]\tLoss: 1.509220\n",
      "Training Epoch: 0 [33280/60000 (55%)]\tLoss: 1.505720\n",
      "Training Epoch: 0 [33920/60000 (57%)]\tLoss: 1.511160\n",
      "Training Epoch: 0 [34560/60000 (58%)]\tLoss: 1.496617\n",
      "Training Epoch: 0 [35200/60000 (59%)]\tLoss: 1.541548\n",
      "Training Epoch: 0 [35840/60000 (60%)]\tLoss: 1.519251\n",
      "Training Epoch: 0 [36480/60000 (61%)]\tLoss: 1.532552\n",
      "Training Epoch: 0 [37120/60000 (62%)]\tLoss: 1.540395\n",
      "Training Epoch: 0 [37760/60000 (63%)]\tLoss: 1.535846\n",
      "Training Epoch: 0 [38400/60000 (64%)]\tLoss: 1.560698\n",
      "Training Epoch: 0 [39040/60000 (65%)]\tLoss: 1.563802\n",
      "Training Epoch: 0 [39680/60000 (66%)]\tLoss: 1.519239\n",
      "Training Epoch: 0 [40320/60000 (67%)]\tLoss: 1.542604\n",
      "Training Epoch: 0 [40960/60000 (68%)]\tLoss: 1.531974\n",
      "Training Epoch: 0 [41600/60000 (69%)]\tLoss: 1.519532\n",
      "Training Epoch: 0 [42240/60000 (70%)]\tLoss: 1.513886\n",
      "Training Epoch: 0 [42880/60000 (71%)]\tLoss: 1.494455\n",
      "Training Epoch: 0 [43520/60000 (72%)]\tLoss: 1.475921\n",
      "Training Epoch: 0 [44160/60000 (74%)]\tLoss: 1.504924\n",
      "Training Epoch: 0 [44800/60000 (75%)]\tLoss: 1.509370\n",
      "Training Epoch: 0 [45440/60000 (76%)]\tLoss: 1.518259\n",
      "Training Epoch: 0 [46080/60000 (77%)]\tLoss: 1.529837\n",
      "Training Epoch: 0 [46720/60000 (78%)]\tLoss: 1.499400\n",
      "Training Epoch: 0 [47360/60000 (79%)]\tLoss: 1.504327\n",
      "Training Epoch: 0 [48000/60000 (80%)]\tLoss: 1.490565\n",
      "Training Epoch: 0 [48640/60000 (81%)]\tLoss: 1.531474\n",
      "Training Epoch: 0 [49280/60000 (82%)]\tLoss: 1.546184\n",
      "Training Epoch: 0 [49920/60000 (83%)]\tLoss: 1.481725\n",
      "Training Epoch: 0 [50560/60000 (84%)]\tLoss: 1.498503\n",
      "Training Epoch: 0 [51200/60000 (85%)]\tLoss: 1.524140\n",
      "Training Epoch: 0 [51840/60000 (86%)]\tLoss: 1.486001\n",
      "Training Epoch: 0 [52480/60000 (87%)]\tLoss: 1.543720\n",
      "Training Epoch: 0 [53120/60000 (88%)]\tLoss: 1.505681\n",
      "Training Epoch: 0 [53760/60000 (90%)]\tLoss: 1.518082\n",
      "Training Epoch: 0 [54400/60000 (91%)]\tLoss: 1.534413\n",
      "Training Epoch: 0 [55040/60000 (92%)]\tLoss: 1.507581\n",
      "Training Epoch: 0 [55680/60000 (93%)]\tLoss: 1.559512\n",
      "Training Epoch: 0 [56320/60000 (94%)]\tLoss: 1.469566\n",
      "Training Epoch: 0 [56960/60000 (95%)]\tLoss: 1.513841\n",
      "Training Epoch: 0 [57600/60000 (96%)]\tLoss: 1.519475\n",
      "Training Epoch: 0 [58240/60000 (97%)]\tLoss: 1.502300\n",
      "Training Epoch: 0 [58880/60000 (98%)]\tLoss: 1.505058\n",
      "Training Epoch: 0 [59520/60000 (99%)]\tLoss: 1.491621\n",
      "Total training loss for epoch : 0 loss: 1.5263644277668202 accuracy: 94.24166666666666\n",
      "Training Epoch: 1 [0/60000 (0%)]\tLoss: 1.521187\n",
      "Training Epoch: 1 [640/60000 (1%)]\tLoss: 1.501521\n",
      "Training Epoch: 1 [1280/60000 (2%)]\tLoss: 1.534725\n",
      "Training Epoch: 1 [1920/60000 (3%)]\tLoss: 1.489455\n",
      "Training Epoch: 1 [2560/60000 (4%)]\tLoss: 1.474025\n",
      "Training Epoch: 1 [3200/60000 (5%)]\tLoss: 1.496804\n",
      "Training Epoch: 1 [3840/60000 (6%)]\tLoss: 1.532369\n",
      "Training Epoch: 1 [4480/60000 (7%)]\tLoss: 1.523273\n",
      "Training Epoch: 1 [5120/60000 (9%)]\tLoss: 1.499354\n",
      "Training Epoch: 1 [5760/60000 (10%)]\tLoss: 1.510248\n",
      "Training Epoch: 1 [6400/60000 (11%)]\tLoss: 1.523308\n",
      "Training Epoch: 1 [7040/60000 (12%)]\tLoss: 1.484807\n",
      "Training Epoch: 1 [7680/60000 (13%)]\tLoss: 1.485662\n",
      "Training Epoch: 1 [8320/60000 (14%)]\tLoss: 1.490237\n",
      "Training Epoch: 1 [8960/60000 (15%)]\tLoss: 1.528599\n",
      "Training Epoch: 1 [9600/60000 (16%)]\tLoss: 1.490734\n",
      "Training Epoch: 1 [10240/60000 (17%)]\tLoss: 1.537284\n",
      "Training Epoch: 1 [10880/60000 (18%)]\tLoss: 1.519980\n",
      "Training Epoch: 1 [11520/60000 (19%)]\tLoss: 1.480241\n",
      "Training Epoch: 1 [12160/60000 (20%)]\tLoss: 1.473631\n",
      "Training Epoch: 1 [12800/60000 (21%)]\tLoss: 1.515668\n",
      "Training Epoch: 1 [13440/60000 (22%)]\tLoss: 1.512332\n",
      "Training Epoch: 1 [14080/60000 (23%)]\tLoss: 1.506495\n",
      "Training Epoch: 1 [14720/60000 (25%)]\tLoss: 1.481310\n",
      "Training Epoch: 1 [15360/60000 (26%)]\tLoss: 1.478349\n",
      "Training Epoch: 1 [16000/60000 (27%)]\tLoss: 1.473790\n",
      "Training Epoch: 1 [16640/60000 (28%)]\tLoss: 1.561277\n",
      "Training Epoch: 1 [17280/60000 (29%)]\tLoss: 1.479126\n",
      "Training Epoch: 1 [17920/60000 (30%)]\tLoss: 1.467533\n",
      "Training Epoch: 1 [18560/60000 (31%)]\tLoss: 1.484332\n",
      "Training Epoch: 1 [19200/60000 (32%)]\tLoss: 1.512029\n",
      "Training Epoch: 1 [19840/60000 (33%)]\tLoss: 1.462931\n",
      "Training Epoch: 1 [20480/60000 (34%)]\tLoss: 1.507036\n",
      "Training Epoch: 1 [21120/60000 (35%)]\tLoss: 1.513599\n",
      "Training Epoch: 1 [21760/60000 (36%)]\tLoss: 1.497869\n",
      "Training Epoch: 1 [22400/60000 (37%)]\tLoss: 1.516343\n",
      "Training Epoch: 1 [23040/60000 (38%)]\tLoss: 1.500948\n",
      "Training Epoch: 1 [23680/60000 (39%)]\tLoss: 1.523684\n",
      "Training Epoch: 1 [24320/60000 (41%)]\tLoss: 1.503756\n",
      "Training Epoch: 1 [24960/60000 (42%)]\tLoss: 1.496489\n",
      "Training Epoch: 1 [25600/60000 (43%)]\tLoss: 1.490476\n",
      "Training Epoch: 1 [26240/60000 (44%)]\tLoss: 1.511297\n",
      "Training Epoch: 1 [26880/60000 (45%)]\tLoss: 1.506029\n",
      "Training Epoch: 1 [27520/60000 (46%)]\tLoss: 1.517940\n",
      "Training Epoch: 1 [28160/60000 (47%)]\tLoss: 1.506418\n",
      "Training Epoch: 1 [28800/60000 (48%)]\tLoss: 1.504485\n",
      "Training Epoch: 1 [29440/60000 (49%)]\tLoss: 1.477072\n",
      "Training Epoch: 1 [30080/60000 (50%)]\tLoss: 1.501829\n",
      "Training Epoch: 1 [30720/60000 (51%)]\tLoss: 1.514580\n",
      "Training Epoch: 1 [31360/60000 (52%)]\tLoss: 1.532903\n",
      "Training Epoch: 1 [32000/60000 (53%)]\tLoss: 1.477002\n",
      "Training Epoch: 1 [32640/60000 (54%)]\tLoss: 1.466491\n",
      "Training Epoch: 1 [33280/60000 (55%)]\tLoss: 1.513611\n",
      "Training Epoch: 1 [33920/60000 (57%)]\tLoss: 1.500334\n",
      "Training Epoch: 1 [34560/60000 (58%)]\tLoss: 1.490190\n",
      "Training Epoch: 1 [35200/60000 (59%)]\tLoss: 1.495836\n",
      "Training Epoch: 1 [35840/60000 (60%)]\tLoss: 1.507616\n",
      "Training Epoch: 1 [36480/60000 (61%)]\tLoss: 1.490430\n",
      "Training Epoch: 1 [37120/60000 (62%)]\tLoss: 1.512021\n",
      "Training Epoch: 1 [37760/60000 (63%)]\tLoss: 1.502210\n",
      "Training Epoch: 1 [38400/60000 (64%)]\tLoss: 1.462377\n",
      "Training Epoch: 1 [39040/60000 (65%)]\tLoss: 1.495075\n",
      "Training Epoch: 1 [39680/60000 (66%)]\tLoss: 1.502052\n",
      "Training Epoch: 1 [40320/60000 (67%)]\tLoss: 1.475581\n",
      "Training Epoch: 1 [40960/60000 (68%)]\tLoss: 1.532155\n",
      "Training Epoch: 1 [41600/60000 (69%)]\tLoss: 1.500565\n",
      "Training Epoch: 1 [42240/60000 (70%)]\tLoss: 1.500938\n",
      "Training Epoch: 1 [42880/60000 (71%)]\tLoss: 1.507243\n",
      "Training Epoch: 1 [43520/60000 (72%)]\tLoss: 1.545852\n",
      "Training Epoch: 1 [44160/60000 (74%)]\tLoss: 1.513758\n",
      "Training Epoch: 1 [44800/60000 (75%)]\tLoss: 1.492740\n",
      "Training Epoch: 1 [45440/60000 (76%)]\tLoss: 1.513764\n",
      "Training Epoch: 1 [46080/60000 (77%)]\tLoss: 1.524903\n",
      "Training Epoch: 1 [46720/60000 (78%)]\tLoss: 1.508924\n",
      "Training Epoch: 1 [47360/60000 (79%)]\tLoss: 1.472978\n",
      "Training Epoch: 1 [48000/60000 (80%)]\tLoss: 1.527959\n",
      "Training Epoch: 1 [48640/60000 (81%)]\tLoss: 1.491081\n",
      "Training Epoch: 1 [49280/60000 (82%)]\tLoss: 1.513632\n",
      "Training Epoch: 1 [49920/60000 (83%)]\tLoss: 1.481386\n",
      "Training Epoch: 1 [50560/60000 (84%)]\tLoss: 1.486167\n",
      "Training Epoch: 1 [51200/60000 (85%)]\tLoss: 1.525248\n",
      "Training Epoch: 1 [51840/60000 (86%)]\tLoss: 1.479164\n",
      "Training Epoch: 1 [52480/60000 (87%)]\tLoss: 1.473308\n",
      "Training Epoch: 1 [53120/60000 (88%)]\tLoss: 1.494486\n",
      "Training Epoch: 1 [53760/60000 (90%)]\tLoss: 1.528527\n",
      "Training Epoch: 1 [54400/60000 (91%)]\tLoss: 1.481654\n",
      "Training Epoch: 1 [55040/60000 (92%)]\tLoss: 1.522853\n",
      "Training Epoch: 1 [55680/60000 (93%)]\tLoss: 1.508106\n",
      "Training Epoch: 1 [56320/60000 (94%)]\tLoss: 1.553266\n",
      "Training Epoch: 1 [56960/60000 (95%)]\tLoss: 1.494939\n",
      "Training Epoch: 1 [57600/60000 (96%)]\tLoss: 1.489287\n",
      "Training Epoch: 1 [58240/60000 (97%)]\tLoss: 1.517416\n",
      "Training Epoch: 1 [58880/60000 (98%)]\tLoss: 1.551009\n",
      "Training Epoch: 1 [59520/60000 (99%)]\tLoss: 1.478636\n",
      "Total training loss for epoch : 1 loss: 1.5029883191529623 accuracy: 96.21333333333334\n",
      "Total training loss across epochs : 2 loss: 1.5146763734598911 accuracy: 95.22749999999999\n",
      "Testing Loss: 1.496 | Accuracy: 96.927\n",
      "Training Epoch: 0 [0/60000 (0%)]\tLoss: 1.479794\n",
      "Training Epoch: 0 [640/60000 (1%)]\tLoss: 1.484310\n",
      "Training Epoch: 0 [1280/60000 (2%)]\tLoss: 1.526335\n",
      "Training Epoch: 0 [1920/60000 (3%)]\tLoss: 1.528479\n",
      "Training Epoch: 0 [2560/60000 (4%)]\tLoss: 1.494294\n",
      "Training Epoch: 0 [3200/60000 (5%)]\tLoss: 1.492947\n",
      "Training Epoch: 0 [3840/60000 (6%)]\tLoss: 1.466685\n",
      "Training Epoch: 0 [4480/60000 (7%)]\tLoss: 1.554107\n",
      "Training Epoch: 0 [5120/60000 (9%)]\tLoss: 1.496108\n",
      "Training Epoch: 0 [5760/60000 (10%)]\tLoss: 1.480743\n",
      "Training Epoch: 0 [6400/60000 (11%)]\tLoss: 1.480749\n",
      "Training Epoch: 0 [7040/60000 (12%)]\tLoss: 1.480058\n",
      "Training Epoch: 0 [7680/60000 (13%)]\tLoss: 1.516208\n",
      "Training Epoch: 0 [8320/60000 (14%)]\tLoss: 1.552201\n",
      "Training Epoch: 0 [8960/60000 (15%)]\tLoss: 1.511360\n",
      "Training Epoch: 0 [9600/60000 (16%)]\tLoss: 1.479710\n",
      "Training Epoch: 0 [10240/60000 (17%)]\tLoss: 1.502667\n",
      "Training Epoch: 0 [10880/60000 (18%)]\tLoss: 1.478688\n",
      "Training Epoch: 0 [11520/60000 (19%)]\tLoss: 1.513750\n",
      "Training Epoch: 0 [12160/60000 (20%)]\tLoss: 1.497824\n",
      "Training Epoch: 0 [12800/60000 (21%)]\tLoss: 1.515386\n",
      "Training Epoch: 0 [13440/60000 (22%)]\tLoss: 1.500465\n",
      "Training Epoch: 0 [14080/60000 (23%)]\tLoss: 1.507017\n",
      "Training Epoch: 0 [14720/60000 (25%)]\tLoss: 1.507607\n",
      "Training Epoch: 0 [15360/60000 (26%)]\tLoss: 1.486138\n",
      "Training Epoch: 0 [16000/60000 (27%)]\tLoss: 1.488865\n",
      "Training Epoch: 0 [16640/60000 (28%)]\tLoss: 1.509408\n",
      "Training Epoch: 0 [17280/60000 (29%)]\tLoss: 1.482371\n",
      "Training Epoch: 0 [17920/60000 (30%)]\tLoss: 1.462981\n",
      "Training Epoch: 0 [18560/60000 (31%)]\tLoss: 1.492030\n",
      "Training Epoch: 0 [19200/60000 (32%)]\tLoss: 1.476709\n",
      "Training Epoch: 0 [19840/60000 (33%)]\tLoss: 1.519539\n",
      "Training Epoch: 0 [20480/60000 (34%)]\tLoss: 1.479274\n",
      "Training Epoch: 0 [21120/60000 (35%)]\tLoss: 1.465970\n",
      "Training Epoch: 0 [21760/60000 (36%)]\tLoss: 1.507063\n",
      "Training Epoch: 0 [22400/60000 (37%)]\tLoss: 1.501673\n",
      "Training Epoch: 0 [23040/60000 (38%)]\tLoss: 1.497046\n",
      "Training Epoch: 0 [23680/60000 (39%)]\tLoss: 1.492904\n",
      "Training Epoch: 0 [24320/60000 (41%)]\tLoss: 1.480319\n",
      "Training Epoch: 0 [24960/60000 (42%)]\tLoss: 1.490037\n",
      "Training Epoch: 0 [25600/60000 (43%)]\tLoss: 1.551797\n",
      "Training Epoch: 0 [26240/60000 (44%)]\tLoss: 1.519962\n",
      "Training Epoch: 0 [26880/60000 (45%)]\tLoss: 1.475951\n",
      "Training Epoch: 0 [27520/60000 (46%)]\tLoss: 1.462553\n",
      "Training Epoch: 0 [28160/60000 (47%)]\tLoss: 1.479954\n",
      "Training Epoch: 0 [28800/60000 (48%)]\tLoss: 1.479609\n",
      "Training Epoch: 0 [29440/60000 (49%)]\tLoss: 1.493074\n",
      "Training Epoch: 0 [30080/60000 (50%)]\tLoss: 1.478661\n",
      "Training Epoch: 0 [30720/60000 (51%)]\tLoss: 1.483730\n",
      "Training Epoch: 0 [31360/60000 (52%)]\tLoss: 1.485645\n",
      "Training Epoch: 0 [32000/60000 (53%)]\tLoss: 1.504694\n",
      "Training Epoch: 0 [32640/60000 (54%)]\tLoss: 1.475162\n",
      "Training Epoch: 0 [33280/60000 (55%)]\tLoss: 1.503133\n",
      "Training Epoch: 0 [33920/60000 (57%)]\tLoss: 1.535792\n",
      "Training Epoch: 0 [34560/60000 (58%)]\tLoss: 1.480608\n",
      "Training Epoch: 0 [35200/60000 (59%)]\tLoss: 1.504511\n",
      "Training Epoch: 0 [35840/60000 (60%)]\tLoss: 1.478089\n",
      "Training Epoch: 0 [36480/60000 (61%)]\tLoss: 1.496760\n",
      "Training Epoch: 0 [37120/60000 (62%)]\tLoss: 1.522175\n",
      "Training Epoch: 0 [37760/60000 (63%)]\tLoss: 1.490132\n",
      "Training Epoch: 0 [38400/60000 (64%)]\tLoss: 1.503441\n",
      "Training Epoch: 0 [39040/60000 (65%)]\tLoss: 1.493039\n",
      "Training Epoch: 0 [39680/60000 (66%)]\tLoss: 1.489415\n",
      "Training Epoch: 0 [40320/60000 (67%)]\tLoss: 1.501311\n",
      "Training Epoch: 0 [40960/60000 (68%)]\tLoss: 1.487355\n",
      "Training Epoch: 0 [41600/60000 (69%)]\tLoss: 1.474162\n",
      "Training Epoch: 0 [42240/60000 (70%)]\tLoss: 1.526605\n",
      "Training Epoch: 0 [42880/60000 (71%)]\tLoss: 1.461923\n",
      "Training Epoch: 0 [43520/60000 (72%)]\tLoss: 1.491118\n",
      "Training Epoch: 0 [44160/60000 (74%)]\tLoss: 1.477141\n",
      "Training Epoch: 0 [44800/60000 (75%)]\tLoss: 1.508937\n",
      "Training Epoch: 0 [45440/60000 (76%)]\tLoss: 1.468871\n",
      "Training Epoch: 0 [46080/60000 (77%)]\tLoss: 1.496445\n",
      "Training Epoch: 0 [46720/60000 (78%)]\tLoss: 1.497161\n",
      "Training Epoch: 0 [47360/60000 (79%)]\tLoss: 1.519299\n",
      "Training Epoch: 0 [48000/60000 (80%)]\tLoss: 1.488129\n",
      "Training Epoch: 0 [48640/60000 (81%)]\tLoss: 1.500656\n",
      "Training Epoch: 0 [49280/60000 (82%)]\tLoss: 1.479816\n",
      "Training Epoch: 0 [49920/60000 (83%)]\tLoss: 1.481812\n",
      "Training Epoch: 0 [50560/60000 (84%)]\tLoss: 1.510145\n",
      "Training Epoch: 0 [51200/60000 (85%)]\tLoss: 1.482362\n",
      "Training Epoch: 0 [51840/60000 (86%)]\tLoss: 1.468849\n",
      "Training Epoch: 0 [52480/60000 (87%)]\tLoss: 1.475336\n",
      "Training Epoch: 0 [53120/60000 (88%)]\tLoss: 1.492409\n",
      "Training Epoch: 0 [53760/60000 (90%)]\tLoss: 1.488352\n",
      "Training Epoch: 0 [54400/60000 (91%)]\tLoss: 1.485689\n",
      "Training Epoch: 0 [55040/60000 (92%)]\tLoss: 1.488449\n",
      "Training Epoch: 0 [55680/60000 (93%)]\tLoss: 1.510432\n",
      "Training Epoch: 0 [56320/60000 (94%)]\tLoss: 1.497837\n",
      "Training Epoch: 0 [56960/60000 (95%)]\tLoss: 1.497287\n",
      "Training Epoch: 0 [57600/60000 (96%)]\tLoss: 1.498364\n",
      "Training Epoch: 0 [58240/60000 (97%)]\tLoss: 1.494444\n",
      "Training Epoch: 0 [58880/60000 (98%)]\tLoss: 1.479141\n",
      "Training Epoch: 0 [59520/60000 (99%)]\tLoss: 1.483750\n",
      "Total training loss for epoch : 0 loss: 1.493469264842808 accuracy: 97.01333333333334\n",
      "Training Epoch: 1 [0/60000 (0%)]\tLoss: 1.464661\n",
      "Training Epoch: 1 [640/60000 (1%)]\tLoss: 1.476900\n",
      "Training Epoch: 1 [1280/60000 (2%)]\tLoss: 1.474834\n",
      "Training Epoch: 1 [1920/60000 (3%)]\tLoss: 1.519387\n",
      "Training Epoch: 1 [2560/60000 (4%)]\tLoss: 1.474836\n",
      "Training Epoch: 1 [3200/60000 (5%)]\tLoss: 1.462628\n",
      "Training Epoch: 1 [3840/60000 (6%)]\tLoss: 1.472715\n",
      "Training Epoch: 1 [4480/60000 (7%)]\tLoss: 1.477240\n",
      "Training Epoch: 1 [5120/60000 (9%)]\tLoss: 1.500521\n",
      "Training Epoch: 1 [5760/60000 (10%)]\tLoss: 1.525717\n",
      "Training Epoch: 1 [6400/60000 (11%)]\tLoss: 1.485068\n",
      "Training Epoch: 1 [7040/60000 (12%)]\tLoss: 1.465653\n",
      "Training Epoch: 1 [7680/60000 (13%)]\tLoss: 1.486853\n",
      "Training Epoch: 1 [8320/60000 (14%)]\tLoss: 1.467354\n",
      "Training Epoch: 1 [8960/60000 (15%)]\tLoss: 1.488755\n",
      "Training Epoch: 1 [9600/60000 (16%)]\tLoss: 1.478807\n",
      "Training Epoch: 1 [10240/60000 (17%)]\tLoss: 1.495046\n",
      "Training Epoch: 1 [10880/60000 (18%)]\tLoss: 1.471849\n",
      "Training Epoch: 1 [11520/60000 (19%)]\tLoss: 1.490162\n",
      "Training Epoch: 1 [12160/60000 (20%)]\tLoss: 1.498073\n",
      "Training Epoch: 1 [12800/60000 (21%)]\tLoss: 1.496230\n",
      "Training Epoch: 1 [13440/60000 (22%)]\tLoss: 1.469746\n",
      "Training Epoch: 1 [14080/60000 (23%)]\tLoss: 1.476948\n",
      "Training Epoch: 1 [14720/60000 (25%)]\tLoss: 1.514780\n",
      "Training Epoch: 1 [15360/60000 (26%)]\tLoss: 1.505947\n",
      "Training Epoch: 1 [16000/60000 (27%)]\tLoss: 1.465229\n",
      "Training Epoch: 1 [16640/60000 (28%)]\tLoss: 1.498141\n",
      "Training Epoch: 1 [17280/60000 (29%)]\tLoss: 1.504348\n",
      "Training Epoch: 1 [17920/60000 (30%)]\tLoss: 1.493346\n",
      "Training Epoch: 1 [18560/60000 (31%)]\tLoss: 1.498864\n",
      "Training Epoch: 1 [19200/60000 (32%)]\tLoss: 1.492988\n",
      "Training Epoch: 1 [19840/60000 (33%)]\tLoss: 1.513856\n",
      "Training Epoch: 1 [20480/60000 (34%)]\tLoss: 1.482474\n",
      "Training Epoch: 1 [21120/60000 (35%)]\tLoss: 1.496601\n",
      "Training Epoch: 1 [21760/60000 (36%)]\tLoss: 1.531584\n",
      "Training Epoch: 1 [22400/60000 (37%)]\tLoss: 1.508144\n",
      "Training Epoch: 1 [23040/60000 (38%)]\tLoss: 1.477596\n",
      "Training Epoch: 1 [23680/60000 (39%)]\tLoss: 1.472259\n",
      "Training Epoch: 1 [24320/60000 (41%)]\tLoss: 1.462491\n",
      "Training Epoch: 1 [24960/60000 (42%)]\tLoss: 1.491623\n",
      "Training Epoch: 1 [25600/60000 (43%)]\tLoss: 1.518454\n",
      "Training Epoch: 1 [26240/60000 (44%)]\tLoss: 1.464883\n",
      "Training Epoch: 1 [26880/60000 (45%)]\tLoss: 1.513408\n",
      "Training Epoch: 1 [27520/60000 (46%)]\tLoss: 1.496012\n",
      "Training Epoch: 1 [28160/60000 (47%)]\tLoss: 1.484996\n",
      "Training Epoch: 1 [28800/60000 (48%)]\tLoss: 1.479400\n",
      "Training Epoch: 1 [29440/60000 (49%)]\tLoss: 1.495045\n",
      "Training Epoch: 1 [30080/60000 (50%)]\tLoss: 1.483855\n",
      "Training Epoch: 1 [30720/60000 (51%)]\tLoss: 1.478918\n",
      "Training Epoch: 1 [31360/60000 (52%)]\tLoss: 1.485186\n",
      "Training Epoch: 1 [32000/60000 (53%)]\tLoss: 1.488051\n",
      "Training Epoch: 1 [32640/60000 (54%)]\tLoss: 1.477127\n",
      "Training Epoch: 1 [33280/60000 (55%)]\tLoss: 1.477099\n",
      "Training Epoch: 1 [33920/60000 (57%)]\tLoss: 1.491698\n",
      "Training Epoch: 1 [34560/60000 (58%)]\tLoss: 1.516170\n",
      "Training Epoch: 1 [35200/60000 (59%)]\tLoss: 1.497494\n",
      "Training Epoch: 1 [35840/60000 (60%)]\tLoss: 1.463569\n",
      "Training Epoch: 1 [36480/60000 (61%)]\tLoss: 1.510620\n",
      "Training Epoch: 1 [37120/60000 (62%)]\tLoss: 1.490001\n",
      "Training Epoch: 1 [37760/60000 (63%)]\tLoss: 1.491759\n",
      "Training Epoch: 1 [38400/60000 (64%)]\tLoss: 1.481999\n",
      "Training Epoch: 1 [39040/60000 (65%)]\tLoss: 1.481395\n",
      "Training Epoch: 1 [39680/60000 (66%)]\tLoss: 1.464076\n",
      "Training Epoch: 1 [40320/60000 (67%)]\tLoss: 1.499680\n",
      "Training Epoch: 1 [40960/60000 (68%)]\tLoss: 1.494435\n",
      "Training Epoch: 1 [41600/60000 (69%)]\tLoss: 1.466745\n",
      "Training Epoch: 1 [42240/60000 (70%)]\tLoss: 1.509602\n",
      "Training Epoch: 1 [42880/60000 (71%)]\tLoss: 1.474557\n",
      "Training Epoch: 1 [43520/60000 (72%)]\tLoss: 1.505495\n",
      "Training Epoch: 1 [44160/60000 (74%)]\tLoss: 1.461989\n",
      "Training Epoch: 1 [44800/60000 (75%)]\tLoss: 1.499543\n",
      "Training Epoch: 1 [45440/60000 (76%)]\tLoss: 1.489771\n",
      "Training Epoch: 1 [46080/60000 (77%)]\tLoss: 1.494223\n",
      "Training Epoch: 1 [46720/60000 (78%)]\tLoss: 1.461679\n",
      "Training Epoch: 1 [47360/60000 (79%)]\tLoss: 1.483044\n",
      "Training Epoch: 1 [48000/60000 (80%)]\tLoss: 1.474825\n",
      "Training Epoch: 1 [48640/60000 (81%)]\tLoss: 1.548872\n",
      "Training Epoch: 1 [49280/60000 (82%)]\tLoss: 1.479410\n",
      "Training Epoch: 1 [49920/60000 (83%)]\tLoss: 1.489663\n",
      "Training Epoch: 1 [50560/60000 (84%)]\tLoss: 1.476981\n",
      "Training Epoch: 1 [51200/60000 (85%)]\tLoss: 1.461754\n",
      "Training Epoch: 1 [51840/60000 (86%)]\tLoss: 1.501032\n",
      "Training Epoch: 1 [52480/60000 (87%)]\tLoss: 1.490495\n",
      "Training Epoch: 1 [53120/60000 (88%)]\tLoss: 1.476705\n",
      "Training Epoch: 1 [53760/60000 (90%)]\tLoss: 1.468410\n",
      "Training Epoch: 1 [54400/60000 (91%)]\tLoss: 1.469106\n",
      "Training Epoch: 1 [55040/60000 (92%)]\tLoss: 1.476869\n",
      "Training Epoch: 1 [55680/60000 (93%)]\tLoss: 1.507865\n",
      "Training Epoch: 1 [56320/60000 (94%)]\tLoss: 1.465682\n",
      "Training Epoch: 1 [56960/60000 (95%)]\tLoss: 1.483310\n",
      "Training Epoch: 1 [57600/60000 (96%)]\tLoss: 1.493260\n",
      "Training Epoch: 1 [58240/60000 (97%)]\tLoss: 1.483357\n",
      "Training Epoch: 1 [58880/60000 (98%)]\tLoss: 1.488561\n",
      "Training Epoch: 1 [59520/60000 (99%)]\tLoss: 1.484157\n",
      "Total training loss for epoch : 1 loss: 1.4881219764762341 accuracy: 97.47666666666667\n",
      "Training Epoch: 2 [0/60000 (0%)]\tLoss: 1.477440\n",
      "Training Epoch: 2 [640/60000 (1%)]\tLoss: 1.472688\n",
      "Training Epoch: 2 [1280/60000 (2%)]\tLoss: 1.469138\n",
      "Training Epoch: 2 [1920/60000 (3%)]\tLoss: 1.471191\n",
      "Training Epoch: 2 [2560/60000 (4%)]\tLoss: 1.463552\n",
      "Training Epoch: 2 [3200/60000 (5%)]\tLoss: 1.471889\n",
      "Training Epoch: 2 [3840/60000 (6%)]\tLoss: 1.508181\n",
      "Training Epoch: 2 [4480/60000 (7%)]\tLoss: 1.500961\n",
      "Training Epoch: 2 [5120/60000 (9%)]\tLoss: 1.473186\n",
      "Training Epoch: 2 [5760/60000 (10%)]\tLoss: 1.478032\n",
      "Training Epoch: 2 [6400/60000 (11%)]\tLoss: 1.464610\n",
      "Training Epoch: 2 [7040/60000 (12%)]\tLoss: 1.488287\n",
      "Training Epoch: 2 [7680/60000 (13%)]\tLoss: 1.481126\n",
      "Training Epoch: 2 [8320/60000 (14%)]\tLoss: 1.472580\n",
      "Training Epoch: 2 [8960/60000 (15%)]\tLoss: 1.501234\n",
      "Training Epoch: 2 [9600/60000 (16%)]\tLoss: 1.516420\n",
      "Training Epoch: 2 [10240/60000 (17%)]\tLoss: 1.497132\n",
      "Training Epoch: 2 [10880/60000 (18%)]\tLoss: 1.509849\n",
      "Training Epoch: 2 [11520/60000 (19%)]\tLoss: 1.476611\n",
      "Training Epoch: 2 [12160/60000 (20%)]\tLoss: 1.461397\n",
      "Training Epoch: 2 [12800/60000 (21%)]\tLoss: 1.517651\n",
      "Training Epoch: 2 [13440/60000 (22%)]\tLoss: 1.476996\n",
      "Training Epoch: 2 [14080/60000 (23%)]\tLoss: 1.524668\n",
      "Training Epoch: 2 [14720/60000 (25%)]\tLoss: 1.512773\n",
      "Training Epoch: 2 [15360/60000 (26%)]\tLoss: 1.479231\n",
      "Training Epoch: 2 [16000/60000 (27%)]\tLoss: 1.526673\n",
      "Training Epoch: 2 [16640/60000 (28%)]\tLoss: 1.482031\n",
      "Training Epoch: 2 [17280/60000 (29%)]\tLoss: 1.462201\n",
      "Training Epoch: 2 [17920/60000 (30%)]\tLoss: 1.476500\n",
      "Training Epoch: 2 [18560/60000 (31%)]\tLoss: 1.485059\n",
      "Training Epoch: 2 [19200/60000 (32%)]\tLoss: 1.467587\n",
      "Training Epoch: 2 [19840/60000 (33%)]\tLoss: 1.470184\n",
      "Training Epoch: 2 [20480/60000 (34%)]\tLoss: 1.503074\n",
      "Training Epoch: 2 [21120/60000 (35%)]\tLoss: 1.478192\n",
      "Training Epoch: 2 [21760/60000 (36%)]\tLoss: 1.480612\n",
      "Training Epoch: 2 [22400/60000 (37%)]\tLoss: 1.482584\n",
      "Training Epoch: 2 [23040/60000 (38%)]\tLoss: 1.485954\n",
      "Training Epoch: 2 [23680/60000 (39%)]\tLoss: 1.496079\n",
      "Training Epoch: 2 [24320/60000 (41%)]\tLoss: 1.461496\n",
      "Training Epoch: 2 [24960/60000 (42%)]\tLoss: 1.477854\n",
      "Training Epoch: 2 [25600/60000 (43%)]\tLoss: 1.477536\n",
      "Training Epoch: 2 [26240/60000 (44%)]\tLoss: 1.503254\n",
      "Training Epoch: 2 [26880/60000 (45%)]\tLoss: 1.461748\n",
      "Training Epoch: 2 [27520/60000 (46%)]\tLoss: 1.477695\n",
      "Training Epoch: 2 [28160/60000 (47%)]\tLoss: 1.467046\n",
      "Training Epoch: 2 [28800/60000 (48%)]\tLoss: 1.493153\n",
      "Training Epoch: 2 [29440/60000 (49%)]\tLoss: 1.473288\n",
      "Training Epoch: 2 [30080/60000 (50%)]\tLoss: 1.479287\n",
      "Training Epoch: 2 [30720/60000 (51%)]\tLoss: 1.473797\n",
      "Training Epoch: 2 [31360/60000 (52%)]\tLoss: 1.489641\n",
      "Training Epoch: 2 [32000/60000 (53%)]\tLoss: 1.470066\n",
      "Training Epoch: 2 [32640/60000 (54%)]\tLoss: 1.461735\n",
      "Training Epoch: 2 [33280/60000 (55%)]\tLoss: 1.477841\n",
      "Training Epoch: 2 [33920/60000 (57%)]\tLoss: 1.484329\n",
      "Training Epoch: 2 [34560/60000 (58%)]\tLoss: 1.492938\n",
      "Training Epoch: 2 [35200/60000 (59%)]\tLoss: 1.483499\n",
      "Training Epoch: 2 [35840/60000 (60%)]\tLoss: 1.498420\n",
      "Training Epoch: 2 [36480/60000 (61%)]\tLoss: 1.486440\n",
      "Training Epoch: 2 [37120/60000 (62%)]\tLoss: 1.463757\n",
      "Training Epoch: 2 [37760/60000 (63%)]\tLoss: 1.476032\n",
      "Training Epoch: 2 [38400/60000 (64%)]\tLoss: 1.484086\n",
      "Training Epoch: 2 [39040/60000 (65%)]\tLoss: 1.477056\n",
      "Training Epoch: 2 [39680/60000 (66%)]\tLoss: 1.483164\n",
      "Training Epoch: 2 [40320/60000 (67%)]\tLoss: 1.515516\n",
      "Training Epoch: 2 [40960/60000 (68%)]\tLoss: 1.463434\n",
      "Training Epoch: 2 [41600/60000 (69%)]\tLoss: 1.477031\n",
      "Training Epoch: 2 [42240/60000 (70%)]\tLoss: 1.497709\n",
      "Training Epoch: 2 [42880/60000 (71%)]\tLoss: 1.475566\n",
      "Training Epoch: 2 [43520/60000 (72%)]\tLoss: 1.487270\n",
      "Training Epoch: 2 [44160/60000 (74%)]\tLoss: 1.481192\n",
      "Training Epoch: 2 [44800/60000 (75%)]\tLoss: 1.476245\n",
      "Training Epoch: 2 [45440/60000 (76%)]\tLoss: 1.490108\n",
      "Training Epoch: 2 [46080/60000 (77%)]\tLoss: 1.477186\n",
      "Training Epoch: 2 [46720/60000 (78%)]\tLoss: 1.518946\n",
      "Training Epoch: 2 [47360/60000 (79%)]\tLoss: 1.476743\n",
      "Training Epoch: 2 [48000/60000 (80%)]\tLoss: 1.486168\n",
      "Training Epoch: 2 [48640/60000 (81%)]\tLoss: 1.496770\n",
      "Training Epoch: 2 [49280/60000 (82%)]\tLoss: 1.485077\n",
      "Training Epoch: 2 [49920/60000 (83%)]\tLoss: 1.492551\n",
      "Training Epoch: 2 [50560/60000 (84%)]\tLoss: 1.461436\n",
      "Training Epoch: 2 [51200/60000 (85%)]\tLoss: 1.464958\n",
      "Training Epoch: 2 [51840/60000 (86%)]\tLoss: 1.470007\n",
      "Training Epoch: 2 [52480/60000 (87%)]\tLoss: 1.493206\n",
      "Training Epoch: 2 [53120/60000 (88%)]\tLoss: 1.480971\n",
      "Training Epoch: 2 [53760/60000 (90%)]\tLoss: 1.471411\n",
      "Training Epoch: 2 [54400/60000 (91%)]\tLoss: 1.503698\n",
      "Training Epoch: 2 [55040/60000 (92%)]\tLoss: 1.461391\n",
      "Training Epoch: 2 [55680/60000 (93%)]\tLoss: 1.505839\n",
      "Training Epoch: 2 [56320/60000 (94%)]\tLoss: 1.507073\n",
      "Training Epoch: 2 [56960/60000 (95%)]\tLoss: 1.507390\n",
      "Training Epoch: 2 [57600/60000 (96%)]\tLoss: 1.503568\n",
      "Training Epoch: 2 [58240/60000 (97%)]\tLoss: 1.487735\n",
      "Training Epoch: 2 [58880/60000 (98%)]\tLoss: 1.490386\n",
      "Training Epoch: 2 [59520/60000 (99%)]\tLoss: 1.476794\n",
      "Total training loss for epoch : 2 loss: 1.4837527624579634 accuracy: 97.92333333333333\n",
      "Total training loss across epochs : 3 loss: 1.4884480012590018 accuracy: 97.47111111111111\n",
      "Testing Loss: 1.482 | Accuracy: 98.047\n"
     ]
    }
   ],
   "source": [
    "best = optimize()\n",
    "\n",
    "lr = best.best_params_['lr']\n",
    "initweights = best.best_params_['module__initweights']\n",
    "usebias = best.best_params_['module__usebias']\n",
    "hiddenunits = best.best_params_['module__hiddenunits']\n",
    "\n",
    "print(\"Initializing Neural Network with GridSearchCV Params...\")\n",
    "print(\"lr: {}, initweights: {}, usebias: {}, hiddenunits: {}\".format(lr, initweights, usebias, hiddenunits))\n",
    "\n",
    "initializeModel(lr, initweights, usebias, hiddenunits)\n",
    "\n",
    "trainlosses = []\n",
    "traincounter = []\n",
    "testlosses = []\n",
    "\n",
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 8: Experiment 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model: CNN(\n",
      "  (conv_1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (conv_2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (max_pool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear_1): Linear(in_features=1568, out_features=64, bias=False)\n",
      "  (linear_2): Linear(in_features=64, out_features=128, bias=False)\n",
      "  (linear_3): Linear(in_features=128, out_features=10, bias=False)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Testing Loss: 2.303 | Accuracy: 9.930\n",
      "Training Epoch: 0 [0/60000 (0%)]\tLoss: 2.306560\n",
      "Training Epoch: 0 [640/60000 (1%)]\tLoss: 2.298435\n",
      "Training Epoch: 0 [1280/60000 (2%)]\tLoss: 2.308378\n",
      "Training Epoch: 0 [1920/60000 (3%)]\tLoss: 2.293922\n",
      "Training Epoch: 0 [2560/60000 (4%)]\tLoss: 2.306113\n",
      "Training Epoch: 0 [3200/60000 (5%)]\tLoss: 2.308174\n",
      "Training Epoch: 0 [3840/60000 (6%)]\tLoss: 2.300500\n",
      "Training Epoch: 0 [4480/60000 (7%)]\tLoss: 2.289921\n",
      "Training Epoch: 0 [5120/60000 (9%)]\tLoss: 2.309243\n",
      "Training Epoch: 0 [5760/60000 (10%)]\tLoss: 2.288513\n",
      "Training Epoch: 0 [6400/60000 (11%)]\tLoss: 2.298368\n",
      "Training Epoch: 0 [7040/60000 (12%)]\tLoss: 2.307443\n",
      "Training Epoch: 0 [7680/60000 (13%)]\tLoss: 2.306182\n",
      "Training Epoch: 0 [8320/60000 (14%)]\tLoss: 2.311705\n",
      "Training Epoch: 0 [8960/60000 (15%)]\tLoss: 2.312855\n",
      "Training Epoch: 0 [9600/60000 (16%)]\tLoss: 2.300740\n",
      "Training Epoch: 0 [10240/60000 (17%)]\tLoss: 2.287522\n",
      "Training Epoch: 0 [10880/60000 (18%)]\tLoss: 2.290050\n",
      "Training Epoch: 0 [11520/60000 (19%)]\tLoss: 2.300078\n",
      "Training Epoch: 0 [12160/60000 (20%)]\tLoss: 2.295765\n",
      "Training Epoch: 0 [12800/60000 (21%)]\tLoss: 2.306798\n",
      "Training Epoch: 0 [13440/60000 (22%)]\tLoss: 2.300416\n",
      "Training Epoch: 0 [14080/60000 (23%)]\tLoss: 2.296377\n",
      "Training Epoch: 0 [14720/60000 (25%)]\tLoss: 2.300330\n",
      "Training Epoch: 0 [15360/60000 (26%)]\tLoss: 2.306459\n",
      "Training Epoch: 0 [16000/60000 (27%)]\tLoss: 2.299690\n",
      "Training Epoch: 0 [16640/60000 (28%)]\tLoss: 2.297985\n",
      "Training Epoch: 0 [17280/60000 (29%)]\tLoss: 2.290236\n",
      "Training Epoch: 0 [17920/60000 (30%)]\tLoss: 2.301452\n",
      "Training Epoch: 0 [18560/60000 (31%)]\tLoss: 2.309928\n",
      "Training Epoch: 0 [19200/60000 (32%)]\tLoss: 2.309079\n",
      "Training Epoch: 0 [19840/60000 (33%)]\tLoss: 2.305784\n",
      "Training Epoch: 0 [20480/60000 (34%)]\tLoss: 2.306024\n",
      "Training Epoch: 0 [21120/60000 (35%)]\tLoss: 2.306558\n",
      "Training Epoch: 0 [21760/60000 (36%)]\tLoss: 2.319165\n",
      "Training Epoch: 0 [22400/60000 (37%)]\tLoss: 2.291075\n",
      "Training Epoch: 0 [23040/60000 (38%)]\tLoss: 2.287859\n",
      "Training Epoch: 0 [23680/60000 (39%)]\tLoss: 2.289902\n",
      "Training Epoch: 0 [24320/60000 (41%)]\tLoss: 2.303468\n",
      "Training Epoch: 0 [24960/60000 (42%)]\tLoss: 2.313354\n",
      "Training Epoch: 0 [25600/60000 (43%)]\tLoss: 2.295934\n",
      "Training Epoch: 0 [26240/60000 (44%)]\tLoss: 2.291330\n",
      "Training Epoch: 0 [26880/60000 (45%)]\tLoss: 2.303656\n",
      "Training Epoch: 0 [27520/60000 (46%)]\tLoss: 2.305854\n",
      "Training Epoch: 0 [28160/60000 (47%)]\tLoss: 2.291373\n",
      "Training Epoch: 0 [28800/60000 (48%)]\tLoss: 2.305582\n",
      "Training Epoch: 0 [29440/60000 (49%)]\tLoss: 2.294446\n",
      "Training Epoch: 0 [30080/60000 (50%)]\tLoss: 2.291524\n",
      "Training Epoch: 0 [30720/60000 (51%)]\tLoss: 2.295623\n",
      "Training Epoch: 0 [31360/60000 (52%)]\tLoss: 2.301321\n",
      "Training Epoch: 0 [32000/60000 (53%)]\tLoss: 2.302640\n",
      "Training Epoch: 0 [32640/60000 (54%)]\tLoss: 2.302511\n",
      "Training Epoch: 0 [33280/60000 (55%)]\tLoss: 2.301970\n",
      "Training Epoch: 0 [33920/60000 (57%)]\tLoss: 2.300122\n",
      "Training Epoch: 0 [34560/60000 (58%)]\tLoss: 2.291503\n",
      "Training Epoch: 0 [35200/60000 (59%)]\tLoss: 2.289334\n",
      "Training Epoch: 0 [35840/60000 (60%)]\tLoss: 2.244460\n",
      "Training Epoch: 0 [36480/60000 (61%)]\tLoss: 2.229215\n",
      "Training Epoch: 0 [37120/60000 (62%)]\tLoss: 2.218597\n",
      "Training Epoch: 0 [37760/60000 (63%)]\tLoss: 2.172701\n",
      "Training Epoch: 0 [38400/60000 (64%)]\tLoss: 2.089649\n",
      "Training Epoch: 0 [39040/60000 (65%)]\tLoss: 2.177620\n",
      "Training Epoch: 0 [39680/60000 (66%)]\tLoss: 2.146660\n",
      "Training Epoch: 0 [40320/60000 (67%)]\tLoss: 2.107783\n",
      "Training Epoch: 0 [40960/60000 (68%)]\tLoss: 2.109124\n",
      "Training Epoch: 0 [41600/60000 (69%)]\tLoss: 2.080525\n",
      "Training Epoch: 0 [42240/60000 (70%)]\tLoss: 2.027192\n",
      "Training Epoch: 0 [42880/60000 (71%)]\tLoss: 1.937389\n",
      "Training Epoch: 0 [43520/60000 (72%)]\tLoss: 1.954118\n",
      "Training Epoch: 0 [44160/60000 (74%)]\tLoss: 1.942176\n",
      "Training Epoch: 0 [44800/60000 (75%)]\tLoss: 1.982977\n",
      "Training Epoch: 0 [45440/60000 (76%)]\tLoss: 2.057749\n",
      "Training Epoch: 0 [46080/60000 (77%)]\tLoss: 1.924511\n",
      "Training Epoch: 0 [46720/60000 (78%)]\tLoss: 1.876382\n",
      "Training Epoch: 0 [47360/60000 (79%)]\tLoss: 1.868464\n",
      "Training Epoch: 0 [48000/60000 (80%)]\tLoss: 1.962594\n",
      "Training Epoch: 0 [48640/60000 (81%)]\tLoss: 1.970492\n",
      "Training Epoch: 0 [49280/60000 (82%)]\tLoss: 1.927007\n",
      "Training Epoch: 0 [49920/60000 (83%)]\tLoss: 1.838382\n",
      "Training Epoch: 0 [50560/60000 (84%)]\tLoss: 1.906372\n",
      "Training Epoch: 0 [51200/60000 (85%)]\tLoss: 1.906551\n",
      "Training Epoch: 0 [51840/60000 (86%)]\tLoss: 1.956476\n",
      "Training Epoch: 0 [52480/60000 (87%)]\tLoss: 1.928189\n",
      "Training Epoch: 0 [53120/60000 (88%)]\tLoss: 1.801400\n",
      "Training Epoch: 0 [53760/60000 (90%)]\tLoss: 1.928057\n",
      "Training Epoch: 0 [54400/60000 (91%)]\tLoss: 1.839132\n",
      "Training Epoch: 0 [55040/60000 (92%)]\tLoss: 1.802593\n",
      "Training Epoch: 0 [55680/60000 (93%)]\tLoss: 1.883534\n",
      "Training Epoch: 0 [56320/60000 (94%)]\tLoss: 1.804485\n",
      "Training Epoch: 0 [56960/60000 (95%)]\tLoss: 1.824509\n",
      "Training Epoch: 0 [57600/60000 (96%)]\tLoss: 1.949051\n",
      "Training Epoch: 0 [58240/60000 (97%)]\tLoss: 1.784521\n",
      "Training Epoch: 0 [58880/60000 (98%)]\tLoss: 1.895712\n",
      "Training Epoch: 0 [59520/60000 (99%)]\tLoss: 1.823696\n",
      "Total training loss for epoch : 0 loss: 2.1732876774852974 accuracy: 26.701666666666668\n",
      "Total training loss across epochs : 1 loss: 2.1732876774852974 accuracy: 26.701666666666668\n",
      "Testing Loss: 1.844 | Accuracy: 63.215\n",
      "Training Epoch: 0 [0/60000 (0%)]\tLoss: 1.865203\n",
      "Training Epoch: 0 [640/60000 (1%)]\tLoss: 1.961882\n",
      "Training Epoch: 0 [1280/60000 (2%)]\tLoss: 1.866260\n",
      "Training Epoch: 0 [1920/60000 (3%)]\tLoss: 1.851080\n",
      "Training Epoch: 0 [2560/60000 (4%)]\tLoss: 1.853746\n",
      "Training Epoch: 0 [3200/60000 (5%)]\tLoss: 1.747540\n",
      "Training Epoch: 0 [3840/60000 (6%)]\tLoss: 1.807114\n",
      "Training Epoch: 0 [4480/60000 (7%)]\tLoss: 1.791357\n",
      "Training Epoch: 0 [5120/60000 (9%)]\tLoss: 1.853058\n",
      "Training Epoch: 0 [5760/60000 (10%)]\tLoss: 1.927177\n",
      "Training Epoch: 0 [6400/60000 (11%)]\tLoss: 1.869215\n",
      "Training Epoch: 0 [7040/60000 (12%)]\tLoss: 1.778234\n",
      "Training Epoch: 0 [7680/60000 (13%)]\tLoss: 1.751465\n",
      "Training Epoch: 0 [8320/60000 (14%)]\tLoss: 1.805206\n",
      "Training Epoch: 0 [8960/60000 (15%)]\tLoss: 1.738177\n",
      "Training Epoch: 0 [9600/60000 (16%)]\tLoss: 1.884465\n",
      "Training Epoch: 0 [10240/60000 (17%)]\tLoss: 1.711063\n",
      "Training Epoch: 0 [10880/60000 (18%)]\tLoss: 1.833627\n",
      "Training Epoch: 0 [11520/60000 (19%)]\tLoss: 1.726028\n",
      "Training Epoch: 0 [12160/60000 (20%)]\tLoss: 1.774778\n",
      "Training Epoch: 0 [12800/60000 (21%)]\tLoss: 1.709560\n",
      "Training Epoch: 0 [13440/60000 (22%)]\tLoss: 1.755473\n",
      "Training Epoch: 0 [14080/60000 (23%)]\tLoss: 1.808860\n",
      "Training Epoch: 0 [14720/60000 (25%)]\tLoss: 1.827410\n",
      "Training Epoch: 0 [15360/60000 (26%)]\tLoss: 1.717708\n",
      "Training Epoch: 0 [16000/60000 (27%)]\tLoss: 1.728006\n",
      "Training Epoch: 0 [16640/60000 (28%)]\tLoss: 1.628623\n",
      "Training Epoch: 0 [17280/60000 (29%)]\tLoss: 1.758452\n",
      "Training Epoch: 0 [17920/60000 (30%)]\tLoss: 1.808946\n",
      "Training Epoch: 0 [18560/60000 (31%)]\tLoss: 1.674723\n",
      "Training Epoch: 0 [19200/60000 (32%)]\tLoss: 1.689315\n",
      "Training Epoch: 0 [19840/60000 (33%)]\tLoss: 1.794169\n",
      "Training Epoch: 0 [20480/60000 (34%)]\tLoss: 1.714542\n",
      "Training Epoch: 0 [21120/60000 (35%)]\tLoss: 1.784585\n",
      "Training Epoch: 0 [21760/60000 (36%)]\tLoss: 1.663434\n",
      "Training Epoch: 0 [22400/60000 (37%)]\tLoss: 1.683885\n",
      "Training Epoch: 0 [23040/60000 (38%)]\tLoss: 1.732693\n",
      "Training Epoch: 0 [23680/60000 (39%)]\tLoss: 1.757489\n",
      "Training Epoch: 0 [24320/60000 (41%)]\tLoss: 1.647997\n",
      "Training Epoch: 0 [24960/60000 (42%)]\tLoss: 1.624740\n",
      "Training Epoch: 0 [25600/60000 (43%)]\tLoss: 1.735860\n",
      "Training Epoch: 0 [26240/60000 (44%)]\tLoss: 1.689152\n",
      "Training Epoch: 0 [26880/60000 (45%)]\tLoss: 1.613099\n",
      "Training Epoch: 0 [27520/60000 (46%)]\tLoss: 1.695381\n",
      "Training Epoch: 0 [28160/60000 (47%)]\tLoss: 1.721968\n",
      "Training Epoch: 0 [28800/60000 (48%)]\tLoss: 1.638720\n",
      "Training Epoch: 0 [29440/60000 (49%)]\tLoss: 1.880126\n",
      "Training Epoch: 0 [30080/60000 (50%)]\tLoss: 1.742924\n",
      "Training Epoch: 0 [30720/60000 (51%)]\tLoss: 1.673545\n",
      "Training Epoch: 0 [31360/60000 (52%)]\tLoss: 1.797065\n",
      "Training Epoch: 0 [32000/60000 (53%)]\tLoss: 1.692426\n",
      "Training Epoch: 0 [32640/60000 (54%)]\tLoss: 1.758809\n",
      "Training Epoch: 0 [33280/60000 (55%)]\tLoss: 1.735101\n",
      "Training Epoch: 0 [33920/60000 (57%)]\tLoss: 1.683559\n",
      "Training Epoch: 0 [34560/60000 (58%)]\tLoss: 1.710224\n",
      "Training Epoch: 0 [35200/60000 (59%)]\tLoss: 1.674728\n",
      "Training Epoch: 0 [35840/60000 (60%)]\tLoss: 1.750113\n",
      "Training Epoch: 0 [36480/60000 (61%)]\tLoss: 1.817127\n",
      "Training Epoch: 0 [37120/60000 (62%)]\tLoss: 1.659822\n",
      "Training Epoch: 0 [37760/60000 (63%)]\tLoss: 1.690434\n",
      "Training Epoch: 0 [38400/60000 (64%)]\tLoss: 1.610548\n",
      "Training Epoch: 0 [39040/60000 (65%)]\tLoss: 1.783776\n",
      "Training Epoch: 0 [39680/60000 (66%)]\tLoss: 1.662106\n",
      "Training Epoch: 0 [40320/60000 (67%)]\tLoss: 1.692682\n",
      "Training Epoch: 0 [40960/60000 (68%)]\tLoss: 1.697829\n",
      "Training Epoch: 0 [41600/60000 (69%)]\tLoss: 1.667517\n",
      "Training Epoch: 0 [42240/60000 (70%)]\tLoss: 1.649413\n",
      "Training Epoch: 0 [42880/60000 (71%)]\tLoss: 1.631953\n",
      "Training Epoch: 0 [43520/60000 (72%)]\tLoss: 1.669422\n",
      "Training Epoch: 0 [44160/60000 (74%)]\tLoss: 1.709093\n",
      "Training Epoch: 0 [44800/60000 (75%)]\tLoss: 1.669600\n",
      "Training Epoch: 0 [45440/60000 (76%)]\tLoss: 1.648822\n",
      "Training Epoch: 0 [46080/60000 (77%)]\tLoss: 1.749167\n",
      "Training Epoch: 0 [46720/60000 (78%)]\tLoss: 1.658637\n",
      "Training Epoch: 0 [47360/60000 (79%)]\tLoss: 1.768554\n",
      "Training Epoch: 0 [48000/60000 (80%)]\tLoss: 1.745239\n",
      "Training Epoch: 0 [48640/60000 (81%)]\tLoss: 1.649770\n",
      "Training Epoch: 0 [49280/60000 (82%)]\tLoss: 1.740893\n",
      "Training Epoch: 0 [49920/60000 (83%)]\tLoss: 1.695779\n",
      "Training Epoch: 0 [50560/60000 (84%)]\tLoss: 1.739483\n",
      "Training Epoch: 0 [51200/60000 (85%)]\tLoss: 1.758400\n",
      "Training Epoch: 0 [51840/60000 (86%)]\tLoss: 1.717486\n",
      "Training Epoch: 0 [52480/60000 (87%)]\tLoss: 1.781041\n",
      "Training Epoch: 0 [53120/60000 (88%)]\tLoss: 1.729323\n",
      "Training Epoch: 0 [53760/60000 (90%)]\tLoss: 1.707957\n",
      "Training Epoch: 0 [54400/60000 (91%)]\tLoss: 1.658632\n",
      "Training Epoch: 0 [55040/60000 (92%)]\tLoss: 1.689918\n",
      "Training Epoch: 0 [55680/60000 (93%)]\tLoss: 1.702743\n",
      "Training Epoch: 0 [56320/60000 (94%)]\tLoss: 1.689491\n",
      "Training Epoch: 0 [56960/60000 (95%)]\tLoss: 1.779964\n",
      "Training Epoch: 0 [57600/60000 (96%)]\tLoss: 1.660115\n",
      "Training Epoch: 0 [58240/60000 (97%)]\tLoss: 1.617479\n",
      "Training Epoch: 0 [58880/60000 (98%)]\tLoss: 1.685699\n",
      "Training Epoch: 0 [59520/60000 (99%)]\tLoss: 1.690012\n",
      "Total training loss for epoch : 0 loss: 1.7329780127702237 accuracy: 73.82166666666667\n",
      "Training Epoch: 1 [0/60000 (0%)]\tLoss: 1.671171\n",
      "Training Epoch: 1 [640/60000 (1%)]\tLoss: 1.651499\n",
      "Training Epoch: 1 [1280/60000 (2%)]\tLoss: 1.720314\n",
      "Training Epoch: 1 [1920/60000 (3%)]\tLoss: 1.688097\n",
      "Training Epoch: 1 [2560/60000 (4%)]\tLoss: 1.584371\n",
      "Training Epoch: 1 [3200/60000 (5%)]\tLoss: 1.673852\n",
      "Training Epoch: 1 [3840/60000 (6%)]\tLoss: 1.621532\n",
      "Training Epoch: 1 [4480/60000 (7%)]\tLoss: 1.675411\n",
      "Training Epoch: 1 [5120/60000 (9%)]\tLoss: 1.612337\n",
      "Training Epoch: 1 [5760/60000 (10%)]\tLoss: 1.612980\n",
      "Training Epoch: 1 [6400/60000 (11%)]\tLoss: 1.567015\n",
      "Training Epoch: 1 [7040/60000 (12%)]\tLoss: 1.636578\n",
      "Training Epoch: 1 [7680/60000 (13%)]\tLoss: 1.607288\n",
      "Training Epoch: 1 [8320/60000 (14%)]\tLoss: 1.708543\n",
      "Training Epoch: 1 [8960/60000 (15%)]\tLoss: 1.658679\n",
      "Training Epoch: 1 [9600/60000 (16%)]\tLoss: 1.595845\n",
      "Training Epoch: 1 [10240/60000 (17%)]\tLoss: 1.599559\n",
      "Training Epoch: 1 [10880/60000 (18%)]\tLoss: 1.629323\n",
      "Training Epoch: 1 [11520/60000 (19%)]\tLoss: 1.703678\n",
      "Training Epoch: 1 [12160/60000 (20%)]\tLoss: 1.597869\n",
      "Training Epoch: 1 [12800/60000 (21%)]\tLoss: 1.628335\n",
      "Training Epoch: 1 [13440/60000 (22%)]\tLoss: 1.646833\n",
      "Training Epoch: 1 [14080/60000 (23%)]\tLoss: 1.603516\n",
      "Training Epoch: 1 [14720/60000 (25%)]\tLoss: 1.719331\n",
      "Training Epoch: 1 [15360/60000 (26%)]\tLoss: 1.583818\n",
      "Training Epoch: 1 [16000/60000 (27%)]\tLoss: 1.581535\n",
      "Training Epoch: 1 [16640/60000 (28%)]\tLoss: 1.683569\n",
      "Training Epoch: 1 [17280/60000 (29%)]\tLoss: 1.552144\n",
      "Training Epoch: 1 [17920/60000 (30%)]\tLoss: 1.646228\n",
      "Training Epoch: 1 [18560/60000 (31%)]\tLoss: 1.635486\n",
      "Training Epoch: 1 [19200/60000 (32%)]\tLoss: 1.661609\n",
      "Training Epoch: 1 [19840/60000 (33%)]\tLoss: 1.582884\n",
      "Training Epoch: 1 [20480/60000 (34%)]\tLoss: 1.578954\n",
      "Training Epoch: 1 [21120/60000 (35%)]\tLoss: 1.588722\n",
      "Training Epoch: 1 [21760/60000 (36%)]\tLoss: 1.575069\n",
      "Training Epoch: 1 [22400/60000 (37%)]\tLoss: 1.731310\n",
      "Training Epoch: 1 [23040/60000 (38%)]\tLoss: 1.682561\n",
      "Training Epoch: 1 [23680/60000 (39%)]\tLoss: 1.622255\n",
      "Training Epoch: 1 [24320/60000 (41%)]\tLoss: 1.545703\n",
      "Training Epoch: 1 [24960/60000 (42%)]\tLoss: 1.603485\n",
      "Training Epoch: 1 [25600/60000 (43%)]\tLoss: 1.618118\n",
      "Training Epoch: 1 [26240/60000 (44%)]\tLoss: 1.638923\n",
      "Training Epoch: 1 [26880/60000 (45%)]\tLoss: 1.662017\n",
      "Training Epoch: 1 [27520/60000 (46%)]\tLoss: 1.557942\n",
      "Training Epoch: 1 [28160/60000 (47%)]\tLoss: 1.595359\n",
      "Training Epoch: 1 [28800/60000 (48%)]\tLoss: 1.606007\n",
      "Training Epoch: 1 [29440/60000 (49%)]\tLoss: 1.611099\n",
      "Training Epoch: 1 [30080/60000 (50%)]\tLoss: 1.584542\n",
      "Training Epoch: 1 [30720/60000 (51%)]\tLoss: 1.637723\n",
      "Training Epoch: 1 [31360/60000 (52%)]\tLoss: 1.633043\n",
      "Training Epoch: 1 [32000/60000 (53%)]\tLoss: 1.631084\n",
      "Training Epoch: 1 [32640/60000 (54%)]\tLoss: 1.590895\n",
      "Training Epoch: 1 [33280/60000 (55%)]\tLoss: 1.555703\n",
      "Training Epoch: 1 [33920/60000 (57%)]\tLoss: 1.573916\n",
      "Training Epoch: 1 [34560/60000 (58%)]\tLoss: 1.559156\n",
      "Training Epoch: 1 [35200/60000 (59%)]\tLoss: 1.573727\n",
      "Training Epoch: 1 [35840/60000 (60%)]\tLoss: 1.537033\n",
      "Training Epoch: 1 [36480/60000 (61%)]\tLoss: 1.525243\n",
      "Training Epoch: 1 [37120/60000 (62%)]\tLoss: 1.604337\n",
      "Training Epoch: 1 [37760/60000 (63%)]\tLoss: 1.595685\n",
      "Training Epoch: 1 [38400/60000 (64%)]\tLoss: 1.605486\n",
      "Training Epoch: 1 [39040/60000 (65%)]\tLoss: 1.561158\n",
      "Training Epoch: 1 [39680/60000 (66%)]\tLoss: 1.541618\n",
      "Training Epoch: 1 [40320/60000 (67%)]\tLoss: 1.582261\n",
      "Training Epoch: 1 [40960/60000 (68%)]\tLoss: 1.557842\n",
      "Training Epoch: 1 [41600/60000 (69%)]\tLoss: 1.627031\n",
      "Training Epoch: 1 [42240/60000 (70%)]\tLoss: 1.574864\n",
      "Training Epoch: 1 [42880/60000 (71%)]\tLoss: 1.524506\n",
      "Training Epoch: 1 [43520/60000 (72%)]\tLoss: 1.575743\n",
      "Training Epoch: 1 [44160/60000 (74%)]\tLoss: 1.546518\n",
      "Training Epoch: 1 [44800/60000 (75%)]\tLoss: 1.621641\n",
      "Training Epoch: 1 [45440/60000 (76%)]\tLoss: 1.549403\n",
      "Training Epoch: 1 [46080/60000 (77%)]\tLoss: 1.569509\n",
      "Training Epoch: 1 [46720/60000 (78%)]\tLoss: 1.541314\n",
      "Training Epoch: 1 [47360/60000 (79%)]\tLoss: 1.538707\n",
      "Training Epoch: 1 [48000/60000 (80%)]\tLoss: 1.527362\n",
      "Training Epoch: 1 [48640/60000 (81%)]\tLoss: 1.553603\n",
      "Training Epoch: 1 [49280/60000 (82%)]\tLoss: 1.530581\n",
      "Training Epoch: 1 [49920/60000 (83%)]\tLoss: 1.565321\n",
      "Training Epoch: 1 [50560/60000 (84%)]\tLoss: 1.496644\n",
      "Training Epoch: 1 [51200/60000 (85%)]\tLoss: 1.514829\n",
      "Training Epoch: 1 [51840/60000 (86%)]\tLoss: 1.538411\n",
      "Training Epoch: 1 [52480/60000 (87%)]\tLoss: 1.501680\n",
      "Training Epoch: 1 [53120/60000 (88%)]\tLoss: 1.525405\n",
      "Training Epoch: 1 [53760/60000 (90%)]\tLoss: 1.557288\n",
      "Training Epoch: 1 [54400/60000 (91%)]\tLoss: 1.570768\n",
      "Training Epoch: 1 [55040/60000 (92%)]\tLoss: 1.536108\n",
      "Training Epoch: 1 [55680/60000 (93%)]\tLoss: 1.546333\n",
      "Training Epoch: 1 [56320/60000 (94%)]\tLoss: 1.574412\n",
      "Training Epoch: 1 [56960/60000 (95%)]\tLoss: 1.541205\n",
      "Training Epoch: 1 [57600/60000 (96%)]\tLoss: 1.538432\n",
      "Training Epoch: 1 [58240/60000 (97%)]\tLoss: 1.565366\n",
      "Training Epoch: 1 [58880/60000 (98%)]\tLoss: 1.564926\n",
      "Training Epoch: 1 [59520/60000 (99%)]\tLoss: 1.530144\n",
      "Total training loss for epoch : 1 loss: 1.5939741791692623 accuracy: 88.00166666666667\n",
      "Total training loss across epochs : 2 loss: 1.663476095969743 accuracy: 80.91166666666666\n",
      "Testing Loss: 1.531 | Accuracy: 93.953\n",
      "Training Epoch: 0 [0/60000 (0%)]\tLoss: 1.573643\n",
      "Training Epoch: 0 [640/60000 (1%)]\tLoss: 1.545292\n",
      "Training Epoch: 0 [1280/60000 (2%)]\tLoss: 1.497723\n",
      "Training Epoch: 0 [1920/60000 (3%)]\tLoss: 1.537240\n",
      "Training Epoch: 0 [2560/60000 (4%)]\tLoss: 1.541763\n",
      "Training Epoch: 0 [3200/60000 (5%)]\tLoss: 1.560293\n",
      "Training Epoch: 0 [3840/60000 (6%)]\tLoss: 1.508980\n",
      "Training Epoch: 0 [4480/60000 (7%)]\tLoss: 1.519361\n",
      "Training Epoch: 0 [5120/60000 (9%)]\tLoss: 1.561884\n",
      "Training Epoch: 0 [5760/60000 (10%)]\tLoss: 1.573385\n",
      "Training Epoch: 0 [6400/60000 (11%)]\tLoss: 1.535214\n",
      "Training Epoch: 0 [7040/60000 (12%)]\tLoss: 1.502228\n",
      "Training Epoch: 0 [7680/60000 (13%)]\tLoss: 1.496942\n",
      "Training Epoch: 0 [8320/60000 (14%)]\tLoss: 1.552044\n",
      "Training Epoch: 0 [8960/60000 (15%)]\tLoss: 1.511361\n",
      "Training Epoch: 0 [9600/60000 (16%)]\tLoss: 1.486336\n",
      "Training Epoch: 0 [10240/60000 (17%)]\tLoss: 1.531831\n",
      "Training Epoch: 0 [10880/60000 (18%)]\tLoss: 1.546760\n",
      "Training Epoch: 0 [11520/60000 (19%)]\tLoss: 1.552767\n",
      "Training Epoch: 0 [12160/60000 (20%)]\tLoss: 1.484632\n",
      "Training Epoch: 0 [12800/60000 (21%)]\tLoss: 1.507626\n",
      "Training Epoch: 0 [13440/60000 (22%)]\tLoss: 1.523395\n",
      "Training Epoch: 0 [14080/60000 (23%)]\tLoss: 1.548213\n",
      "Training Epoch: 0 [14720/60000 (25%)]\tLoss: 1.532841\n",
      "Training Epoch: 0 [15360/60000 (26%)]\tLoss: 1.480663\n",
      "Training Epoch: 0 [16000/60000 (27%)]\tLoss: 1.562591\n",
      "Training Epoch: 0 [16640/60000 (28%)]\tLoss: 1.486581\n",
      "Training Epoch: 0 [17280/60000 (29%)]\tLoss: 1.519330\n",
      "Training Epoch: 0 [17920/60000 (30%)]\tLoss: 1.520990\n",
      "Training Epoch: 0 [18560/60000 (31%)]\tLoss: 1.516308\n",
      "Training Epoch: 0 [19200/60000 (32%)]\tLoss: 1.505503\n",
      "Training Epoch: 0 [19840/60000 (33%)]\tLoss: 1.523393\n",
      "Training Epoch: 0 [20480/60000 (34%)]\tLoss: 1.479290\n",
      "Training Epoch: 0 [21120/60000 (35%)]\tLoss: 1.538690\n",
      "Training Epoch: 0 [21760/60000 (36%)]\tLoss: 1.541240\n",
      "Training Epoch: 0 [22400/60000 (37%)]\tLoss: 1.522686\n",
      "Training Epoch: 0 [23040/60000 (38%)]\tLoss: 1.495649\n",
      "Training Epoch: 0 [23680/60000 (39%)]\tLoss: 1.517087\n",
      "Training Epoch: 0 [24320/60000 (41%)]\tLoss: 1.529104\n",
      "Training Epoch: 0 [24960/60000 (42%)]\tLoss: 1.500915\n",
      "Training Epoch: 0 [25600/60000 (43%)]\tLoss: 1.572467\n",
      "Training Epoch: 0 [26240/60000 (44%)]\tLoss: 1.473755\n",
      "Training Epoch: 0 [26880/60000 (45%)]\tLoss: 1.481338\n",
      "Training Epoch: 0 [27520/60000 (46%)]\tLoss: 1.526389\n",
      "Training Epoch: 0 [28160/60000 (47%)]\tLoss: 1.505030\n",
      "Training Epoch: 0 [28800/60000 (48%)]\tLoss: 1.558934\n",
      "Training Epoch: 0 [29440/60000 (49%)]\tLoss: 1.540514\n",
      "Training Epoch: 0 [30080/60000 (50%)]\tLoss: 1.519090\n",
      "Training Epoch: 0 [30720/60000 (51%)]\tLoss: 1.517216\n",
      "Training Epoch: 0 [31360/60000 (52%)]\tLoss: 1.525826\n",
      "Training Epoch: 0 [32000/60000 (53%)]\tLoss: 1.486235\n",
      "Training Epoch: 0 [32640/60000 (54%)]\tLoss: 1.476792\n",
      "Training Epoch: 0 [33280/60000 (55%)]\tLoss: 1.501063\n",
      "Training Epoch: 0 [33920/60000 (57%)]\tLoss: 1.538214\n",
      "Training Epoch: 0 [34560/60000 (58%)]\tLoss: 1.506955\n",
      "Training Epoch: 0 [35200/60000 (59%)]\tLoss: 1.512408\n",
      "Training Epoch: 0 [35840/60000 (60%)]\tLoss: 1.563899\n",
      "Training Epoch: 0 [36480/60000 (61%)]\tLoss: 1.537638\n",
      "Training Epoch: 0 [37120/60000 (62%)]\tLoss: 1.511964\n",
      "Training Epoch: 0 [37760/60000 (63%)]\tLoss: 1.472843\n",
      "Training Epoch: 0 [38400/60000 (64%)]\tLoss: 1.504823\n",
      "Training Epoch: 0 [39040/60000 (65%)]\tLoss: 1.529865\n",
      "Training Epoch: 0 [39680/60000 (66%)]\tLoss: 1.512186\n",
      "Training Epoch: 0 [40320/60000 (67%)]\tLoss: 1.524650\n",
      "Training Epoch: 0 [40960/60000 (68%)]\tLoss: 1.529365\n",
      "Training Epoch: 0 [41600/60000 (69%)]\tLoss: 1.502033\n",
      "Training Epoch: 0 [42240/60000 (70%)]\tLoss: 1.497442\n",
      "Training Epoch: 0 [42880/60000 (71%)]\tLoss: 1.517311\n",
      "Training Epoch: 0 [43520/60000 (72%)]\tLoss: 1.510789\n",
      "Training Epoch: 0 [44160/60000 (74%)]\tLoss: 1.525822\n",
      "Training Epoch: 0 [44800/60000 (75%)]\tLoss: 1.489289\n",
      "Training Epoch: 0 [45440/60000 (76%)]\tLoss: 1.520936\n",
      "Training Epoch: 0 [46080/60000 (77%)]\tLoss: 1.522581\n",
      "Training Epoch: 0 [46720/60000 (78%)]\tLoss: 1.478909\n",
      "Training Epoch: 0 [47360/60000 (79%)]\tLoss: 1.484893\n",
      "Training Epoch: 0 [48000/60000 (80%)]\tLoss: 1.492859\n",
      "Training Epoch: 0 [48640/60000 (81%)]\tLoss: 1.504567\n",
      "Training Epoch: 0 [49280/60000 (82%)]\tLoss: 1.505907\n",
      "Training Epoch: 0 [49920/60000 (83%)]\tLoss: 1.508542\n",
      "Training Epoch: 0 [50560/60000 (84%)]\tLoss: 1.491321\n",
      "Training Epoch: 0 [51200/60000 (85%)]\tLoss: 1.506874\n",
      "Training Epoch: 0 [51840/60000 (86%)]\tLoss: 1.493252\n",
      "Training Epoch: 0 [52480/60000 (87%)]\tLoss: 1.519577\n",
      "Training Epoch: 0 [53120/60000 (88%)]\tLoss: 1.482607\n",
      "Training Epoch: 0 [53760/60000 (90%)]\tLoss: 1.495539\n",
      "Training Epoch: 0 [54400/60000 (91%)]\tLoss: 1.508188\n",
      "Training Epoch: 0 [55040/60000 (92%)]\tLoss: 1.524669\n",
      "Training Epoch: 0 [55680/60000 (93%)]\tLoss: 1.491155\n",
      "Training Epoch: 0 [56320/60000 (94%)]\tLoss: 1.534894\n",
      "Training Epoch: 0 [56960/60000 (95%)]\tLoss: 1.512143\n",
      "Training Epoch: 0 [57600/60000 (96%)]\tLoss: 1.488166\n",
      "Training Epoch: 0 [58240/60000 (97%)]\tLoss: 1.492973\n",
      "Training Epoch: 0 [58880/60000 (98%)]\tLoss: 1.462742\n",
      "Training Epoch: 0 [59520/60000 (99%)]\tLoss: 1.511979\n",
      "Total training loss for epoch : 0 loss: 1.5187631386683693 accuracy: 94.91166666666666\n",
      "Training Epoch: 1 [0/60000 (0%)]\tLoss: 1.470985\n",
      "Training Epoch: 1 [640/60000 (1%)]\tLoss: 1.524014\n",
      "Training Epoch: 1 [1280/60000 (2%)]\tLoss: 1.523990\n",
      "Training Epoch: 1 [1920/60000 (3%)]\tLoss: 1.489979\n",
      "Training Epoch: 1 [2560/60000 (4%)]\tLoss: 1.480366\n",
      "Training Epoch: 1 [3200/60000 (5%)]\tLoss: 1.484794\n",
      "Training Epoch: 1 [3840/60000 (6%)]\tLoss: 1.498898\n",
      "Training Epoch: 1 [4480/60000 (7%)]\tLoss: 1.518832\n",
      "Training Epoch: 1 [5120/60000 (9%)]\tLoss: 1.527217\n",
      "Training Epoch: 1 [5760/60000 (10%)]\tLoss: 1.506540\n",
      "Training Epoch: 1 [6400/60000 (11%)]\tLoss: 1.500551\n",
      "Training Epoch: 1 [7040/60000 (12%)]\tLoss: 1.484440\n",
      "Training Epoch: 1 [7680/60000 (13%)]\tLoss: 1.547565\n",
      "Training Epoch: 1 [8320/60000 (14%)]\tLoss: 1.506550\n",
      "Training Epoch: 1 [8960/60000 (15%)]\tLoss: 1.519253\n",
      "Training Epoch: 1 [9600/60000 (16%)]\tLoss: 1.520521\n",
      "Training Epoch: 1 [10240/60000 (17%)]\tLoss: 1.496979\n",
      "Training Epoch: 1 [10880/60000 (18%)]\tLoss: 1.493756\n",
      "Training Epoch: 1 [11520/60000 (19%)]\tLoss: 1.496537\n",
      "Training Epoch: 1 [12160/60000 (20%)]\tLoss: 1.495800\n",
      "Training Epoch: 1 [12800/60000 (21%)]\tLoss: 1.480839\n",
      "Training Epoch: 1 [13440/60000 (22%)]\tLoss: 1.486529\n",
      "Training Epoch: 1 [14080/60000 (23%)]\tLoss: 1.507405\n",
      "Training Epoch: 1 [14720/60000 (25%)]\tLoss: 1.529066\n",
      "Training Epoch: 1 [15360/60000 (26%)]\tLoss: 1.569770\n",
      "Training Epoch: 1 [16000/60000 (27%)]\tLoss: 1.472069\n",
      "Training Epoch: 1 [16640/60000 (28%)]\tLoss: 1.482121\n",
      "Training Epoch: 1 [17280/60000 (29%)]\tLoss: 1.485520\n",
      "Training Epoch: 1 [17920/60000 (30%)]\tLoss: 1.510922\n",
      "Training Epoch: 1 [18560/60000 (31%)]\tLoss: 1.490385\n",
      "Training Epoch: 1 [19200/60000 (32%)]\tLoss: 1.530732\n",
      "Training Epoch: 1 [19840/60000 (33%)]\tLoss: 1.514425\n",
      "Training Epoch: 1 [20480/60000 (34%)]\tLoss: 1.512386\n",
      "Training Epoch: 1 [21120/60000 (35%)]\tLoss: 1.526794\n",
      "Training Epoch: 1 [21760/60000 (36%)]\tLoss: 1.504218\n",
      "Training Epoch: 1 [22400/60000 (37%)]\tLoss: 1.545672\n",
      "Training Epoch: 1 [23040/60000 (38%)]\tLoss: 1.531347\n",
      "Training Epoch: 1 [23680/60000 (39%)]\tLoss: 1.529036\n",
      "Training Epoch: 1 [24320/60000 (41%)]\tLoss: 1.489407\n",
      "Training Epoch: 1 [24960/60000 (42%)]\tLoss: 1.500091\n",
      "Training Epoch: 1 [25600/60000 (43%)]\tLoss: 1.507798\n",
      "Training Epoch: 1 [26240/60000 (44%)]\tLoss: 1.487990\n",
      "Training Epoch: 1 [26880/60000 (45%)]\tLoss: 1.490931\n",
      "Training Epoch: 1 [27520/60000 (46%)]\tLoss: 1.555357\n",
      "Training Epoch: 1 [28160/60000 (47%)]\tLoss: 1.506559\n",
      "Training Epoch: 1 [28800/60000 (48%)]\tLoss: 1.509432\n",
      "Training Epoch: 1 [29440/60000 (49%)]\tLoss: 1.505236\n",
      "Training Epoch: 1 [30080/60000 (50%)]\tLoss: 1.472803\n",
      "Training Epoch: 1 [30720/60000 (51%)]\tLoss: 1.529212\n",
      "Training Epoch: 1 [31360/60000 (52%)]\tLoss: 1.499605\n",
      "Training Epoch: 1 [32000/60000 (53%)]\tLoss: 1.493703\n",
      "Training Epoch: 1 [32640/60000 (54%)]\tLoss: 1.505272\n",
      "Training Epoch: 1 [33280/60000 (55%)]\tLoss: 1.521763\n",
      "Training Epoch: 1 [33920/60000 (57%)]\tLoss: 1.546796\n",
      "Training Epoch: 1 [34560/60000 (58%)]\tLoss: 1.534360\n",
      "Training Epoch: 1 [35200/60000 (59%)]\tLoss: 1.474742\n",
      "Training Epoch: 1 [35840/60000 (60%)]\tLoss: 1.519307\n",
      "Training Epoch: 1 [36480/60000 (61%)]\tLoss: 1.516058\n",
      "Training Epoch: 1 [37120/60000 (62%)]\tLoss: 1.514917\n",
      "Training Epoch: 1 [37760/60000 (63%)]\tLoss: 1.480404\n",
      "Training Epoch: 1 [38400/60000 (64%)]\tLoss: 1.512144\n",
      "Training Epoch: 1 [39040/60000 (65%)]\tLoss: 1.468845\n",
      "Training Epoch: 1 [39680/60000 (66%)]\tLoss: 1.513836\n",
      "Training Epoch: 1 [40320/60000 (67%)]\tLoss: 1.516481\n",
      "Training Epoch: 1 [40960/60000 (68%)]\tLoss: 1.504728\n",
      "Training Epoch: 1 [41600/60000 (69%)]\tLoss: 1.519263\n",
      "Training Epoch: 1 [42240/60000 (70%)]\tLoss: 1.510861\n",
      "Training Epoch: 1 [42880/60000 (71%)]\tLoss: 1.490127\n",
      "Training Epoch: 1 [43520/60000 (72%)]\tLoss: 1.541288\n",
      "Training Epoch: 1 [44160/60000 (74%)]\tLoss: 1.480621\n",
      "Training Epoch: 1 [44800/60000 (75%)]\tLoss: 1.523385\n",
      "Training Epoch: 1 [45440/60000 (76%)]\tLoss: 1.499316\n",
      "Training Epoch: 1 [46080/60000 (77%)]\tLoss: 1.480255\n",
      "Training Epoch: 1 [46720/60000 (78%)]\tLoss: 1.485494\n",
      "Training Epoch: 1 [47360/60000 (79%)]\tLoss: 1.510088\n",
      "Training Epoch: 1 [48000/60000 (80%)]\tLoss: 1.510524\n",
      "Training Epoch: 1 [48640/60000 (81%)]\tLoss: 1.504485\n",
      "Training Epoch: 1 [49280/60000 (82%)]\tLoss: 1.546573\n",
      "Training Epoch: 1 [49920/60000 (83%)]\tLoss: 1.504966\n",
      "Training Epoch: 1 [50560/60000 (84%)]\tLoss: 1.492433\n",
      "Training Epoch: 1 [51200/60000 (85%)]\tLoss: 1.543665\n",
      "Training Epoch: 1 [51840/60000 (86%)]\tLoss: 1.482500\n",
      "Training Epoch: 1 [52480/60000 (87%)]\tLoss: 1.491136\n",
      "Training Epoch: 1 [53120/60000 (88%)]\tLoss: 1.486385\n",
      "Training Epoch: 1 [53760/60000 (90%)]\tLoss: 1.468842\n",
      "Training Epoch: 1 [54400/60000 (91%)]\tLoss: 1.478916\n",
      "Training Epoch: 1 [55040/60000 (92%)]\tLoss: 1.485351\n",
      "Training Epoch: 1 [55680/60000 (93%)]\tLoss: 1.553044\n",
      "Training Epoch: 1 [56320/60000 (94%)]\tLoss: 1.541452\n",
      "Training Epoch: 1 [56960/60000 (95%)]\tLoss: 1.490312\n",
      "Training Epoch: 1 [57600/60000 (96%)]\tLoss: 1.508635\n",
      "Training Epoch: 1 [58240/60000 (97%)]\tLoss: 1.509313\n",
      "Training Epoch: 1 [58880/60000 (98%)]\tLoss: 1.498988\n",
      "Training Epoch: 1 [59520/60000 (99%)]\tLoss: 1.508321\n",
      "Total training loss for epoch : 1 loss: 1.5051540957330896 accuracy: 96.015\n",
      "Training Epoch: 2 [0/60000 (0%)]\tLoss: 1.514759\n",
      "Training Epoch: 2 [640/60000 (1%)]\tLoss: 1.478294\n",
      "Training Epoch: 2 [1280/60000 (2%)]\tLoss: 1.506601\n",
      "Training Epoch: 2 [1920/60000 (3%)]\tLoss: 1.466776\n",
      "Training Epoch: 2 [2560/60000 (4%)]\tLoss: 1.521653\n",
      "Training Epoch: 2 [3200/60000 (5%)]\tLoss: 1.502998\n",
      "Training Epoch: 2 [3840/60000 (6%)]\tLoss: 1.491481\n",
      "Training Epoch: 2 [4480/60000 (7%)]\tLoss: 1.470254\n",
      "Training Epoch: 2 [5120/60000 (9%)]\tLoss: 1.490099\n",
      "Training Epoch: 2 [5760/60000 (10%)]\tLoss: 1.462694\n",
      "Training Epoch: 2 [6400/60000 (11%)]\tLoss: 1.521113\n",
      "Training Epoch: 2 [7040/60000 (12%)]\tLoss: 1.537187\n",
      "Training Epoch: 2 [7680/60000 (13%)]\tLoss: 1.481608\n",
      "Training Epoch: 2 [8320/60000 (14%)]\tLoss: 1.488360\n",
      "Training Epoch: 2 [8960/60000 (15%)]\tLoss: 1.517948\n",
      "Training Epoch: 2 [9600/60000 (16%)]\tLoss: 1.485055\n",
      "Training Epoch: 2 [10240/60000 (17%)]\tLoss: 1.505030\n",
      "Training Epoch: 2 [10880/60000 (18%)]\tLoss: 1.462212\n",
      "Training Epoch: 2 [11520/60000 (19%)]\tLoss: 1.498197\n",
      "Training Epoch: 2 [12160/60000 (20%)]\tLoss: 1.505176\n",
      "Training Epoch: 2 [12800/60000 (21%)]\tLoss: 1.523040\n",
      "Training Epoch: 2 [13440/60000 (22%)]\tLoss: 1.496681\n",
      "Training Epoch: 2 [14080/60000 (23%)]\tLoss: 1.495891\n",
      "Training Epoch: 2 [14720/60000 (25%)]\tLoss: 1.503060\n",
      "Training Epoch: 2 [15360/60000 (26%)]\tLoss: 1.493861\n",
      "Training Epoch: 2 [16000/60000 (27%)]\tLoss: 1.480201\n",
      "Training Epoch: 2 [16640/60000 (28%)]\tLoss: 1.528654\n",
      "Training Epoch: 2 [17280/60000 (29%)]\tLoss: 1.480345\n",
      "Training Epoch: 2 [17920/60000 (30%)]\tLoss: 1.505405\n",
      "Training Epoch: 2 [18560/60000 (31%)]\tLoss: 1.522538\n",
      "Training Epoch: 2 [19200/60000 (32%)]\tLoss: 1.515087\n",
      "Training Epoch: 2 [19840/60000 (33%)]\tLoss: 1.493037\n",
      "Training Epoch: 2 [20480/60000 (34%)]\tLoss: 1.462129\n",
      "Training Epoch: 2 [21120/60000 (35%)]\tLoss: 1.542269\n",
      "Training Epoch: 2 [21760/60000 (36%)]\tLoss: 1.528086\n",
      "Training Epoch: 2 [22400/60000 (37%)]\tLoss: 1.492616\n",
      "Training Epoch: 2 [23040/60000 (38%)]\tLoss: 1.491447\n",
      "Training Epoch: 2 [23680/60000 (39%)]\tLoss: 1.479941\n",
      "Training Epoch: 2 [24320/60000 (41%)]\tLoss: 1.482297\n",
      "Training Epoch: 2 [24960/60000 (42%)]\tLoss: 1.513308\n",
      "Training Epoch: 2 [25600/60000 (43%)]\tLoss: 1.492734\n",
      "Training Epoch: 2 [26240/60000 (44%)]\tLoss: 1.513160\n",
      "Training Epoch: 2 [26880/60000 (45%)]\tLoss: 1.512883\n",
      "Training Epoch: 2 [27520/60000 (46%)]\tLoss: 1.489247\n",
      "Training Epoch: 2 [28160/60000 (47%)]\tLoss: 1.497878\n",
      "Training Epoch: 2 [28800/60000 (48%)]\tLoss: 1.476618\n",
      "Training Epoch: 2 [29440/60000 (49%)]\tLoss: 1.482625\n",
      "Training Epoch: 2 [30080/60000 (50%)]\tLoss: 1.470681\n",
      "Training Epoch: 2 [30720/60000 (51%)]\tLoss: 1.472567\n",
      "Training Epoch: 2 [31360/60000 (52%)]\tLoss: 1.477226\n",
      "Training Epoch: 2 [32000/60000 (53%)]\tLoss: 1.473941\n",
      "Training Epoch: 2 [32640/60000 (54%)]\tLoss: 1.491843\n",
      "Training Epoch: 2 [33280/60000 (55%)]\tLoss: 1.479725\n",
      "Training Epoch: 2 [33920/60000 (57%)]\tLoss: 1.508208\n",
      "Training Epoch: 2 [34560/60000 (58%)]\tLoss: 1.489178\n",
      "Training Epoch: 2 [35200/60000 (59%)]\tLoss: 1.482074\n",
      "Training Epoch: 2 [35840/60000 (60%)]\tLoss: 1.495571\n",
      "Training Epoch: 2 [36480/60000 (61%)]\tLoss: 1.464809\n",
      "Training Epoch: 2 [37120/60000 (62%)]\tLoss: 1.503102\n",
      "Training Epoch: 2 [37760/60000 (63%)]\tLoss: 1.554621\n",
      "Training Epoch: 2 [38400/60000 (64%)]\tLoss: 1.477429\n",
      "Training Epoch: 2 [39040/60000 (65%)]\tLoss: 1.505596\n",
      "Training Epoch: 2 [39680/60000 (66%)]\tLoss: 1.474888\n",
      "Training Epoch: 2 [40320/60000 (67%)]\tLoss: 1.483765\n",
      "Training Epoch: 2 [40960/60000 (68%)]\tLoss: 1.484187\n",
      "Training Epoch: 2 [41600/60000 (69%)]\tLoss: 1.501197\n",
      "Training Epoch: 2 [42240/60000 (70%)]\tLoss: 1.502317\n",
      "Training Epoch: 2 [42880/60000 (71%)]\tLoss: 1.472046\n",
      "Training Epoch: 2 [43520/60000 (72%)]\tLoss: 1.509525\n",
      "Training Epoch: 2 [44160/60000 (74%)]\tLoss: 1.499776\n",
      "Training Epoch: 2 [44800/60000 (75%)]\tLoss: 1.502170\n",
      "Training Epoch: 2 [45440/60000 (76%)]\tLoss: 1.514590\n",
      "Training Epoch: 2 [46080/60000 (77%)]\tLoss: 1.462180\n",
      "Training Epoch: 2 [46720/60000 (78%)]\tLoss: 1.506935\n",
      "Training Epoch: 2 [47360/60000 (79%)]\tLoss: 1.475190\n",
      "Training Epoch: 2 [48000/60000 (80%)]\tLoss: 1.481100\n",
      "Training Epoch: 2 [48640/60000 (81%)]\tLoss: 1.482864\n",
      "Training Epoch: 2 [49280/60000 (82%)]\tLoss: 1.478104\n",
      "Training Epoch: 2 [49920/60000 (83%)]\tLoss: 1.502483\n",
      "Training Epoch: 2 [50560/60000 (84%)]\tLoss: 1.514017\n",
      "Training Epoch: 2 [51200/60000 (85%)]\tLoss: 1.467971\n",
      "Training Epoch: 2 [51840/60000 (86%)]\tLoss: 1.512736\n",
      "Training Epoch: 2 [52480/60000 (87%)]\tLoss: 1.506057\n",
      "Training Epoch: 2 [53120/60000 (88%)]\tLoss: 1.540962\n",
      "Training Epoch: 2 [53760/60000 (90%)]\tLoss: 1.465015\n",
      "Training Epoch: 2 [54400/60000 (91%)]\tLoss: 1.484904\n",
      "Training Epoch: 2 [55040/60000 (92%)]\tLoss: 1.505402\n",
      "Training Epoch: 2 [55680/60000 (93%)]\tLoss: 1.498233\n",
      "Training Epoch: 2 [56320/60000 (94%)]\tLoss: 1.544978\n",
      "Training Epoch: 2 [56960/60000 (95%)]\tLoss: 1.497297\n",
      "Training Epoch: 2 [57600/60000 (96%)]\tLoss: 1.494981\n",
      "Training Epoch: 2 [58240/60000 (97%)]\tLoss: 1.512810\n",
      "Training Epoch: 2 [58880/60000 (98%)]\tLoss: 1.500060\n",
      "Training Epoch: 2 [59520/60000 (99%)]\tLoss: 1.504270\n",
      "Total training loss for epoch : 2 loss: 1.4975859230515292 accuracy: 96.635\n",
      "Total training loss across epochs : 3 loss: 1.5071677191509962 accuracy: 95.85388888888889\n",
      "Testing Loss: 1.494 | Accuracy: 96.943\n"
     ]
    }
   ],
   "source": [
    "initializeModel(0.001, False, False, 64)\n",
    "\n",
    "trainlosses = []\n",
    "traincounter = []\n",
    "testlosses = []\n",
    "\n",
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 9: Experiment 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model: CNN(\n",
      "  (conv_1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv_2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (max_pool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear_1): Linear(in_features=1568, out_features=32, bias=True)\n",
      "  (linear_2): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (linear_3): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Testing Loss: 2.305 | Accuracy: 9.930\n",
      "Training Epoch: 0 [0/60000 (0%)]\tLoss: 2.284933\n",
      "Training Epoch: 0 [640/60000 (1%)]\tLoss: 2.287762\n",
      "Training Epoch: 0 [1280/60000 (2%)]\tLoss: 2.295399\n",
      "Training Epoch: 0 [1920/60000 (3%)]\tLoss: 2.308936\n",
      "Training Epoch: 0 [2560/60000 (4%)]\tLoss: 2.320493\n",
      "Training Epoch: 0 [3200/60000 (5%)]\tLoss: 2.287565\n",
      "Training Epoch: 0 [3840/60000 (6%)]\tLoss: 2.309692\n",
      "Training Epoch: 0 [4480/60000 (7%)]\tLoss: 2.311176\n",
      "Training Epoch: 0 [5120/60000 (9%)]\tLoss: 2.310202\n",
      "Training Epoch: 0 [5760/60000 (10%)]\tLoss: 2.307549\n",
      "Training Epoch: 0 [6400/60000 (11%)]\tLoss: 2.290511\n",
      "Training Epoch: 0 [7040/60000 (12%)]\tLoss: 2.306725\n",
      "Training Epoch: 0 [7680/60000 (13%)]\tLoss: 2.303504\n",
      "Training Epoch: 0 [8320/60000 (14%)]\tLoss: 2.302702\n",
      "Training Epoch: 0 [8960/60000 (15%)]\tLoss: 2.304810\n",
      "Training Epoch: 0 [9600/60000 (16%)]\tLoss: 2.293244\n",
      "Training Epoch: 0 [10240/60000 (17%)]\tLoss: 2.309548\n",
      "Training Epoch: 0 [10880/60000 (18%)]\tLoss: 2.309307\n",
      "Training Epoch: 0 [11520/60000 (19%)]\tLoss: 2.295833\n",
      "Training Epoch: 0 [12160/60000 (20%)]\tLoss: 2.303361\n",
      "Training Epoch: 0 [12800/60000 (21%)]\tLoss: 2.299894\n",
      "Training Epoch: 0 [13440/60000 (22%)]\tLoss: 2.298460\n",
      "Training Epoch: 0 [14080/60000 (23%)]\tLoss: 2.308146\n",
      "Training Epoch: 0 [14720/60000 (25%)]\tLoss: 2.300005\n",
      "Training Epoch: 0 [15360/60000 (26%)]\tLoss: 2.296697\n",
      "Training Epoch: 0 [16000/60000 (27%)]\tLoss: 2.287587\n",
      "Training Epoch: 0 [16640/60000 (28%)]\tLoss: 2.289819\n",
      "Training Epoch: 0 [17280/60000 (29%)]\tLoss: 2.287221\n",
      "Training Epoch: 0 [17920/60000 (30%)]\tLoss: 2.299094\n",
      "Training Epoch: 0 [18560/60000 (31%)]\tLoss: 2.303693\n",
      "Training Epoch: 0 [19200/60000 (32%)]\tLoss: 2.282837\n",
      "Training Epoch: 0 [19840/60000 (33%)]\tLoss: 2.294087\n",
      "Training Epoch: 0 [20480/60000 (34%)]\tLoss: 2.312995\n",
      "Training Epoch: 0 [21120/60000 (35%)]\tLoss: 2.298338\n",
      "Training Epoch: 0 [21760/60000 (36%)]\tLoss: 2.302340\n",
      "Training Epoch: 0 [22400/60000 (37%)]\tLoss: 2.289703\n",
      "Training Epoch: 0 [23040/60000 (38%)]\tLoss: 2.300218\n",
      "Training Epoch: 0 [23680/60000 (39%)]\tLoss: 2.298024\n",
      "Training Epoch: 0 [24320/60000 (41%)]\tLoss: 2.283369\n",
      "Training Epoch: 0 [24960/60000 (42%)]\tLoss: 2.304930\n",
      "Training Epoch: 0 [25600/60000 (43%)]\tLoss: 2.315702\n",
      "Training Epoch: 0 [26240/60000 (44%)]\tLoss: 2.288044\n",
      "Training Epoch: 0 [26880/60000 (45%)]\tLoss: 2.299832\n",
      "Training Epoch: 0 [27520/60000 (46%)]\tLoss: 2.303232\n",
      "Training Epoch: 0 [28160/60000 (47%)]\tLoss: 2.295995\n",
      "Training Epoch: 0 [28800/60000 (48%)]\tLoss: 2.307673\n",
      "Training Epoch: 0 [29440/60000 (49%)]\tLoss: 2.300936\n",
      "Training Epoch: 0 [30080/60000 (50%)]\tLoss: 2.308378\n",
      "Training Epoch: 0 [30720/60000 (51%)]\tLoss: 2.301341\n",
      "Training Epoch: 0 [31360/60000 (52%)]\tLoss: 2.301930\n",
      "Training Epoch: 0 [32000/60000 (53%)]\tLoss: 2.300529\n",
      "Training Epoch: 0 [32640/60000 (54%)]\tLoss: 2.331816\n",
      "Training Epoch: 0 [33280/60000 (55%)]\tLoss: 2.308378\n",
      "Training Epoch: 0 [33920/60000 (57%)]\tLoss: 2.305797\n",
      "Training Epoch: 0 [34560/60000 (58%)]\tLoss: 2.307710\n",
      "Training Epoch: 0 [35200/60000 (59%)]\tLoss: 2.297746\n",
      "Training Epoch: 0 [35840/60000 (60%)]\tLoss: 2.301461\n",
      "Training Epoch: 0 [36480/60000 (61%)]\tLoss: 2.298760\n",
      "Training Epoch: 0 [37120/60000 (62%)]\tLoss: 2.307282\n",
      "Training Epoch: 0 [37760/60000 (63%)]\tLoss: 2.306720\n",
      "Training Epoch: 0 [38400/60000 (64%)]\tLoss: 2.303333\n",
      "Training Epoch: 0 [39040/60000 (65%)]\tLoss: 2.307181\n",
      "Training Epoch: 0 [39680/60000 (66%)]\tLoss: 2.297112\n",
      "Training Epoch: 0 [40320/60000 (67%)]\tLoss: 2.301135\n",
      "Training Epoch: 0 [40960/60000 (68%)]\tLoss: 2.304612\n",
      "Training Epoch: 0 [41600/60000 (69%)]\tLoss: 2.309032\n",
      "Training Epoch: 0 [42240/60000 (70%)]\tLoss: 2.297279\n",
      "Training Epoch: 0 [42880/60000 (71%)]\tLoss: 2.308739\n",
      "Training Epoch: 0 [43520/60000 (72%)]\tLoss: 2.307798\n",
      "Training Epoch: 0 [44160/60000 (74%)]\tLoss: 2.301044\n",
      "Training Epoch: 0 [44800/60000 (75%)]\tLoss: 2.305829\n",
      "Training Epoch: 0 [45440/60000 (76%)]\tLoss: 2.292960\n",
      "Training Epoch: 0 [46080/60000 (77%)]\tLoss: 2.297994\n",
      "Training Epoch: 0 [46720/60000 (78%)]\tLoss: 2.298498\n",
      "Training Epoch: 0 [47360/60000 (79%)]\tLoss: 2.297529\n",
      "Training Epoch: 0 [48000/60000 (80%)]\tLoss: 2.297909\n",
      "Training Epoch: 0 [48640/60000 (81%)]\tLoss: 2.306517\n",
      "Training Epoch: 0 [49280/60000 (82%)]\tLoss: 2.308575\n",
      "Training Epoch: 0 [49920/60000 (83%)]\tLoss: 2.303270\n",
      "Training Epoch: 0 [50560/60000 (84%)]\tLoss: 2.303428\n",
      "Training Epoch: 0 [51200/60000 (85%)]\tLoss: 2.302003\n",
      "Training Epoch: 0 [51840/60000 (86%)]\tLoss: 2.306379\n",
      "Training Epoch: 0 [52480/60000 (87%)]\tLoss: 2.296830\n",
      "Training Epoch: 0 [53120/60000 (88%)]\tLoss: 2.309047\n",
      "Training Epoch: 0 [53760/60000 (90%)]\tLoss: 2.292539\n",
      "Training Epoch: 0 [54400/60000 (91%)]\tLoss: 2.300447\n",
      "Training Epoch: 0 [55040/60000 (92%)]\tLoss: 2.309071\n",
      "Training Epoch: 0 [55680/60000 (93%)]\tLoss: 2.299409\n",
      "Training Epoch: 0 [56320/60000 (94%)]\tLoss: 2.301802\n",
      "Training Epoch: 0 [56960/60000 (95%)]\tLoss: 2.301529\n",
      "Training Epoch: 0 [57600/60000 (96%)]\tLoss: 2.300754\n",
      "Training Epoch: 0 [58240/60000 (97%)]\tLoss: 2.297565\n",
      "Training Epoch: 0 [58880/60000 (98%)]\tLoss: 2.298871\n",
      "Training Epoch: 0 [59520/60000 (99%)]\tLoss: 2.294692\n",
      "Total training loss for epoch : 0 loss: 2.3021276157293746 accuracy: 10.998333333333333\n",
      "Total training loss across epochs : 1 loss: 2.3021276157293746 accuracy: 10.998333333333333\n",
      "Testing Loss: 2.301 | Accuracy: 10.442\n",
      "Training Epoch: 0 [0/60000 (0%)]\tLoss: 2.305168\n",
      "Training Epoch: 0 [640/60000 (1%)]\tLoss: 2.299585\n",
      "Training Epoch: 0 [1280/60000 (2%)]\tLoss: 2.304667\n",
      "Training Epoch: 0 [1920/60000 (3%)]\tLoss: 2.295987\n",
      "Training Epoch: 0 [2560/60000 (4%)]\tLoss: 2.301207\n",
      "Training Epoch: 0 [3200/60000 (5%)]\tLoss: 2.302170\n",
      "Training Epoch: 0 [3840/60000 (6%)]\tLoss: 2.301449\n",
      "Training Epoch: 0 [4480/60000 (7%)]\tLoss: 2.305171\n",
      "Training Epoch: 0 [5120/60000 (9%)]\tLoss: 2.301106\n",
      "Training Epoch: 0 [5760/60000 (10%)]\tLoss: 2.301790\n",
      "Training Epoch: 0 [6400/60000 (11%)]\tLoss: 2.313958\n",
      "Training Epoch: 0 [7040/60000 (12%)]\tLoss: 2.296342\n",
      "Training Epoch: 0 [7680/60000 (13%)]\tLoss: 2.291223\n",
      "Training Epoch: 0 [8320/60000 (14%)]\tLoss: 2.294172\n",
      "Training Epoch: 0 [8960/60000 (15%)]\tLoss: 2.294984\n",
      "Training Epoch: 0 [9600/60000 (16%)]\tLoss: 2.307992\n",
      "Training Epoch: 0 [10240/60000 (17%)]\tLoss: 2.302072\n",
      "Training Epoch: 0 [10880/60000 (18%)]\tLoss: 2.295990\n",
      "Training Epoch: 0 [11520/60000 (19%)]\tLoss: 2.303713\n",
      "Training Epoch: 0 [12160/60000 (20%)]\tLoss: 2.287007\n",
      "Training Epoch: 0 [12800/60000 (21%)]\tLoss: 2.308723\n",
      "Training Epoch: 0 [13440/60000 (22%)]\tLoss: 2.295632\n",
      "Training Epoch: 0 [14080/60000 (23%)]\tLoss: 2.308018\n",
      "Training Epoch: 0 [14720/60000 (25%)]\tLoss: 2.300870\n",
      "Training Epoch: 0 [15360/60000 (26%)]\tLoss: 2.303473\n",
      "Training Epoch: 0 [16000/60000 (27%)]\tLoss: 2.305497\n",
      "Training Epoch: 0 [16640/60000 (28%)]\tLoss: 2.289926\n",
      "Training Epoch: 0 [17280/60000 (29%)]\tLoss: 2.302334\n",
      "Training Epoch: 0 [17920/60000 (30%)]\tLoss: 2.299339\n",
      "Training Epoch: 0 [18560/60000 (31%)]\tLoss: 2.299113\n",
      "Training Epoch: 0 [19200/60000 (32%)]\tLoss: 2.305177\n",
      "Training Epoch: 0 [19840/60000 (33%)]\tLoss: 2.307922\n",
      "Training Epoch: 0 [20480/60000 (34%)]\tLoss: 2.299832\n",
      "Training Epoch: 0 [21120/60000 (35%)]\tLoss: 2.297640\n",
      "Training Epoch: 0 [21760/60000 (36%)]\tLoss: 2.301578\n",
      "Training Epoch: 0 [22400/60000 (37%)]\tLoss: 2.289645\n",
      "Training Epoch: 0 [23040/60000 (38%)]\tLoss: 2.304840\n",
      "Training Epoch: 0 [23680/60000 (39%)]\tLoss: 2.303242\n",
      "Training Epoch: 0 [24320/60000 (41%)]\tLoss: 2.304041\n",
      "Training Epoch: 0 [24960/60000 (42%)]\tLoss: 2.310852\n",
      "Training Epoch: 0 [25600/60000 (43%)]\tLoss: 2.291511\n",
      "Training Epoch: 0 [26240/60000 (44%)]\tLoss: 2.307616\n",
      "Training Epoch: 0 [26880/60000 (45%)]\tLoss: 2.305989\n",
      "Training Epoch: 0 [27520/60000 (46%)]\tLoss: 2.304443\n",
      "Training Epoch: 0 [28160/60000 (47%)]\tLoss: 2.279730\n",
      "Training Epoch: 0 [28800/60000 (48%)]\tLoss: 2.295370\n",
      "Training Epoch: 0 [29440/60000 (49%)]\tLoss: 2.299043\n",
      "Training Epoch: 0 [30080/60000 (50%)]\tLoss: 2.296082\n",
      "Training Epoch: 0 [30720/60000 (51%)]\tLoss: 2.293969\n",
      "Training Epoch: 0 [31360/60000 (52%)]\tLoss: 2.288307\n",
      "Training Epoch: 0 [32000/60000 (53%)]\tLoss: 2.300776\n",
      "Training Epoch: 0 [32640/60000 (54%)]\tLoss: 2.304843\n",
      "Training Epoch: 0 [33280/60000 (55%)]\tLoss: 2.291204\n",
      "Training Epoch: 0 [33920/60000 (57%)]\tLoss: 2.302983\n",
      "Training Epoch: 0 [34560/60000 (58%)]\tLoss: 2.305125\n",
      "Training Epoch: 0 [35200/60000 (59%)]\tLoss: 2.297550\n",
      "Training Epoch: 0 [35840/60000 (60%)]\tLoss: 2.298407\n",
      "Training Epoch: 0 [36480/60000 (61%)]\tLoss: 2.295304\n",
      "Training Epoch: 0 [37120/60000 (62%)]\tLoss: 2.295184\n",
      "Training Epoch: 0 [37760/60000 (63%)]\tLoss: 2.306334\n",
      "Training Epoch: 0 [38400/60000 (64%)]\tLoss: 2.297132\n",
      "Training Epoch: 0 [39040/60000 (65%)]\tLoss: 2.299571\n",
      "Training Epoch: 0 [39680/60000 (66%)]\tLoss: 2.307178\n",
      "Training Epoch: 0 [40320/60000 (67%)]\tLoss: 2.293059\n",
      "Training Epoch: 0 [40960/60000 (68%)]\tLoss: 2.302541\n",
      "Training Epoch: 0 [41600/60000 (69%)]\tLoss: 2.292532\n",
      "Training Epoch: 0 [42240/60000 (70%)]\tLoss: 2.302748\n",
      "Training Epoch: 0 [42880/60000 (71%)]\tLoss: 2.302791\n",
      "Training Epoch: 0 [43520/60000 (72%)]\tLoss: 2.302322\n",
      "Training Epoch: 0 [44160/60000 (74%)]\tLoss: 2.300393\n",
      "Training Epoch: 0 [44800/60000 (75%)]\tLoss: 2.304549\n",
      "Training Epoch: 0 [45440/60000 (76%)]\tLoss: 2.312757\n",
      "Training Epoch: 0 [46080/60000 (77%)]\tLoss: 2.316788\n",
      "Training Epoch: 0 [46720/60000 (78%)]\tLoss: 2.303446\n",
      "Training Epoch: 0 [47360/60000 (79%)]\tLoss: 2.301681\n",
      "Training Epoch: 0 [48000/60000 (80%)]\tLoss: 2.292468\n",
      "Training Epoch: 0 [48640/60000 (81%)]\tLoss: 2.308295\n",
      "Training Epoch: 0 [49280/60000 (82%)]\tLoss: 2.304327\n",
      "Training Epoch: 0 [49920/60000 (83%)]\tLoss: 2.307759\n",
      "Training Epoch: 0 [50560/60000 (84%)]\tLoss: 2.296452\n",
      "Training Epoch: 0 [51200/60000 (85%)]\tLoss: 2.293903\n",
      "Training Epoch: 0 [51840/60000 (86%)]\tLoss: 2.296100\n",
      "Training Epoch: 0 [52480/60000 (87%)]\tLoss: 2.307305\n",
      "Training Epoch: 0 [53120/60000 (88%)]\tLoss: 2.299155\n",
      "Training Epoch: 0 [53760/60000 (90%)]\tLoss: 2.295406\n",
      "Training Epoch: 0 [54400/60000 (91%)]\tLoss: 2.305837\n",
      "Training Epoch: 0 [55040/60000 (92%)]\tLoss: 2.304300\n",
      "Training Epoch: 0 [55680/60000 (93%)]\tLoss: 2.297223\n",
      "Training Epoch: 0 [56320/60000 (94%)]\tLoss: 2.299815\n",
      "Training Epoch: 0 [56960/60000 (95%)]\tLoss: 2.304717\n",
      "Training Epoch: 0 [57600/60000 (96%)]\tLoss: 2.296289\n",
      "Training Epoch: 0 [58240/60000 (97%)]\tLoss: 2.299793\n",
      "Training Epoch: 0 [58880/60000 (98%)]\tLoss: 2.310920\n",
      "Training Epoch: 0 [59520/60000 (99%)]\tLoss: 2.305217\n",
      "Total training loss for epoch : 0 loss: 2.30146926247489 accuracy: 11.17\n",
      "Training Epoch: 1 [0/60000 (0%)]\tLoss: 2.289224\n",
      "Training Epoch: 1 [640/60000 (1%)]\tLoss: 2.289672\n",
      "Training Epoch: 1 [1280/60000 (2%)]\tLoss: 2.308566\n",
      "Training Epoch: 1 [1920/60000 (3%)]\tLoss: 2.307002\n",
      "Training Epoch: 1 [2560/60000 (4%)]\tLoss: 2.301778\n",
      "Training Epoch: 1 [3200/60000 (5%)]\tLoss: 2.298057\n",
      "Training Epoch: 1 [3840/60000 (6%)]\tLoss: 2.294790\n",
      "Training Epoch: 1 [4480/60000 (7%)]\tLoss: 2.304052\n",
      "Training Epoch: 1 [5120/60000 (9%)]\tLoss: 2.290921\n",
      "Training Epoch: 1 [5760/60000 (10%)]\tLoss: 2.301573\n",
      "Training Epoch: 1 [6400/60000 (11%)]\tLoss: 2.299580\n",
      "Training Epoch: 1 [7040/60000 (12%)]\tLoss: 2.301635\n",
      "Training Epoch: 1 [7680/60000 (13%)]\tLoss: 2.300147\n",
      "Training Epoch: 1 [8320/60000 (14%)]\tLoss: 2.304412\n",
      "Training Epoch: 1 [8960/60000 (15%)]\tLoss: 2.295900\n",
      "Training Epoch: 1 [9600/60000 (16%)]\tLoss: 2.304615\n",
      "Training Epoch: 1 [10240/60000 (17%)]\tLoss: 2.295466\n",
      "Training Epoch: 1 [10880/60000 (18%)]\tLoss: 2.298953\n",
      "Training Epoch: 1 [11520/60000 (19%)]\tLoss: 2.296666\n",
      "Training Epoch: 1 [12160/60000 (20%)]\tLoss: 2.305156\n",
      "Training Epoch: 1 [12800/60000 (21%)]\tLoss: 2.288299\n",
      "Training Epoch: 1 [13440/60000 (22%)]\tLoss: 2.298301\n",
      "Training Epoch: 1 [14080/60000 (23%)]\tLoss: 2.286551\n",
      "Training Epoch: 1 [14720/60000 (25%)]\tLoss: 2.291401\n",
      "Training Epoch: 1 [15360/60000 (26%)]\tLoss: 2.300181\n",
      "Training Epoch: 1 [16000/60000 (27%)]\tLoss: 2.278503\n",
      "Training Epoch: 1 [16640/60000 (28%)]\tLoss: 2.306199\n",
      "Training Epoch: 1 [17280/60000 (29%)]\tLoss: 2.287381\n",
      "Training Epoch: 1 [17920/60000 (30%)]\tLoss: 2.299441\n",
      "Training Epoch: 1 [18560/60000 (31%)]\tLoss: 2.303984\n",
      "Training Epoch: 1 [19200/60000 (32%)]\tLoss: 2.309659\n",
      "Training Epoch: 1 [19840/60000 (33%)]\tLoss: 2.299832\n",
      "Training Epoch: 1 [20480/60000 (34%)]\tLoss: 2.283574\n",
      "Training Epoch: 1 [21120/60000 (35%)]\tLoss: 2.304900\n",
      "Training Epoch: 1 [21760/60000 (36%)]\tLoss: 2.300087\n",
      "Training Epoch: 1 [22400/60000 (37%)]\tLoss: 2.310129\n",
      "Training Epoch: 1 [23040/60000 (38%)]\tLoss: 2.309664\n",
      "Training Epoch: 1 [23680/60000 (39%)]\tLoss: 2.288676\n",
      "Training Epoch: 1 [24320/60000 (41%)]\tLoss: 2.309423\n",
      "Training Epoch: 1 [24960/60000 (42%)]\tLoss: 2.317906\n",
      "Training Epoch: 1 [25600/60000 (43%)]\tLoss: 2.299389\n",
      "Training Epoch: 1 [26240/60000 (44%)]\tLoss: 2.311294\n",
      "Training Epoch: 1 [26880/60000 (45%)]\tLoss: 2.293140\n",
      "Training Epoch: 1 [27520/60000 (46%)]\tLoss: 2.306566\n",
      "Training Epoch: 1 [28160/60000 (47%)]\tLoss: 2.292333\n",
      "Training Epoch: 1 [28800/60000 (48%)]\tLoss: 2.287856\n",
      "Training Epoch: 1 [29440/60000 (49%)]\tLoss: 2.315399\n",
      "Training Epoch: 1 [30080/60000 (50%)]\tLoss: 2.303946\n",
      "Training Epoch: 1 [30720/60000 (51%)]\tLoss: 2.299416\n",
      "Training Epoch: 1 [31360/60000 (52%)]\tLoss: 2.306274\n",
      "Training Epoch: 1 [32000/60000 (53%)]\tLoss: 2.299250\n",
      "Training Epoch: 1 [32640/60000 (54%)]\tLoss: 2.306124\n",
      "Training Epoch: 1 [33280/60000 (55%)]\tLoss: 2.298326\n",
      "Training Epoch: 1 [33920/60000 (57%)]\tLoss: 2.306298\n",
      "Training Epoch: 1 [34560/60000 (58%)]\tLoss: 2.297052\n",
      "Training Epoch: 1 [35200/60000 (59%)]\tLoss: 2.292435\n",
      "Training Epoch: 1 [35840/60000 (60%)]\tLoss: 2.283861\n",
      "Training Epoch: 1 [36480/60000 (61%)]\tLoss: 2.291286\n",
      "Training Epoch: 1 [37120/60000 (62%)]\tLoss: 2.316552\n",
      "Training Epoch: 1 [37760/60000 (63%)]\tLoss: 2.303835\n",
      "Training Epoch: 1 [38400/60000 (64%)]\tLoss: 2.309979\n",
      "Training Epoch: 1 [39040/60000 (65%)]\tLoss: 2.312091\n",
      "Training Epoch: 1 [39680/60000 (66%)]\tLoss: 2.299613\n",
      "Training Epoch: 1 [40320/60000 (67%)]\tLoss: 2.306875\n",
      "Training Epoch: 1 [40960/60000 (68%)]\tLoss: 2.288538\n",
      "Training Epoch: 1 [41600/60000 (69%)]\tLoss: 2.312979\n",
      "Training Epoch: 1 [42240/60000 (70%)]\tLoss: 2.303682\n",
      "Training Epoch: 1 [42880/60000 (71%)]\tLoss: 2.297999\n",
      "Training Epoch: 1 [43520/60000 (72%)]\tLoss: 2.309032\n",
      "Training Epoch: 1 [44160/60000 (74%)]\tLoss: 2.298478\n",
      "Training Epoch: 1 [44800/60000 (75%)]\tLoss: 2.291724\n",
      "Training Epoch: 1 [45440/60000 (76%)]\tLoss: 2.293407\n",
      "Training Epoch: 1 [46080/60000 (77%)]\tLoss: 2.311494\n",
      "Training Epoch: 1 [46720/60000 (78%)]\tLoss: 2.304789\n",
      "Training Epoch: 1 [47360/60000 (79%)]\tLoss: 2.295988\n",
      "Training Epoch: 1 [48000/60000 (80%)]\tLoss: 2.307303\n",
      "Training Epoch: 1 [48640/60000 (81%)]\tLoss: 2.301225\n",
      "Training Epoch: 1 [49280/60000 (82%)]\tLoss: 2.297795\n",
      "Training Epoch: 1 [49920/60000 (83%)]\tLoss: 2.296481\n",
      "Training Epoch: 1 [50560/60000 (84%)]\tLoss: 2.303764\n",
      "Training Epoch: 1 [51200/60000 (85%)]\tLoss: 2.293014\n",
      "Training Epoch: 1 [51840/60000 (86%)]\tLoss: 2.302712\n",
      "Training Epoch: 1 [52480/60000 (87%)]\tLoss: 2.299612\n",
      "Training Epoch: 1 [53120/60000 (88%)]\tLoss: 2.300064\n",
      "Training Epoch: 1 [53760/60000 (90%)]\tLoss: 2.295487\n",
      "Training Epoch: 1 [54400/60000 (91%)]\tLoss: 2.298926\n",
      "Training Epoch: 1 [55040/60000 (92%)]\tLoss: 2.303793\n",
      "Training Epoch: 1 [55680/60000 (93%)]\tLoss: 2.295677\n",
      "Training Epoch: 1 [56320/60000 (94%)]\tLoss: 2.297929\n",
      "Training Epoch: 1 [56960/60000 (95%)]\tLoss: 2.301656\n",
      "Training Epoch: 1 [57600/60000 (96%)]\tLoss: 2.296441\n",
      "Training Epoch: 1 [58240/60000 (97%)]\tLoss: 2.293798\n",
      "Training Epoch: 1 [58880/60000 (98%)]\tLoss: 2.305270\n",
      "Training Epoch: 1 [59520/60000 (99%)]\tLoss: 2.305997\n",
      "Total training loss for epoch : 1 loss: 2.301371820445762 accuracy: 11.198333333333334\n",
      "Total training loss across epochs : 2 loss: 2.3014205414603257 accuracy: 11.184166666666666\n",
      "Testing Loss: 2.301 | Accuracy: 11.237\n",
      "Training Epoch: 0 [0/60000 (0%)]\tLoss: 2.291314\n",
      "Training Epoch: 0 [640/60000 (1%)]\tLoss: 2.302477\n",
      "Training Epoch: 0 [1280/60000 (2%)]\tLoss: 2.286121\n",
      "Training Epoch: 0 [1920/60000 (3%)]\tLoss: 2.292177\n",
      "Training Epoch: 0 [2560/60000 (4%)]\tLoss: 2.301045\n",
      "Training Epoch: 0 [3200/60000 (5%)]\tLoss: 2.292225\n",
      "Training Epoch: 0 [3840/60000 (6%)]\tLoss: 2.297546\n",
      "Training Epoch: 0 [4480/60000 (7%)]\tLoss: 2.301205\n",
      "Training Epoch: 0 [5120/60000 (9%)]\tLoss: 2.304816\n",
      "Training Epoch: 0 [5760/60000 (10%)]\tLoss: 2.306423\n",
      "Training Epoch: 0 [6400/60000 (11%)]\tLoss: 2.298212\n",
      "Training Epoch: 0 [7040/60000 (12%)]\tLoss: 2.300448\n",
      "Training Epoch: 0 [7680/60000 (13%)]\tLoss: 2.311688\n",
      "Training Epoch: 0 [8320/60000 (14%)]\tLoss: 2.304467\n",
      "Training Epoch: 0 [8960/60000 (15%)]\tLoss: 2.300472\n",
      "Training Epoch: 0 [9600/60000 (16%)]\tLoss: 2.297284\n",
      "Training Epoch: 0 [10240/60000 (17%)]\tLoss: 2.292598\n",
      "Training Epoch: 0 [10880/60000 (18%)]\tLoss: 2.297026\n",
      "Training Epoch: 0 [11520/60000 (19%)]\tLoss: 2.299953\n",
      "Training Epoch: 0 [12160/60000 (20%)]\tLoss: 2.293220\n",
      "Training Epoch: 0 [12800/60000 (21%)]\tLoss: 2.309755\n",
      "Training Epoch: 0 [13440/60000 (22%)]\tLoss: 2.304911\n",
      "Training Epoch: 0 [14080/60000 (23%)]\tLoss: 2.299151\n",
      "Training Epoch: 0 [14720/60000 (25%)]\tLoss: 2.299239\n",
      "Training Epoch: 0 [15360/60000 (26%)]\tLoss: 2.297176\n",
      "Training Epoch: 0 [16000/60000 (27%)]\tLoss: 2.301753\n",
      "Training Epoch: 0 [16640/60000 (28%)]\tLoss: 2.294809\n",
      "Training Epoch: 0 [17280/60000 (29%)]\tLoss: 2.306867\n",
      "Training Epoch: 0 [17920/60000 (30%)]\tLoss: 2.296690\n",
      "Training Epoch: 0 [18560/60000 (31%)]\tLoss: 2.292903\n",
      "Training Epoch: 0 [19200/60000 (32%)]\tLoss: 2.294199\n",
      "Training Epoch: 0 [19840/60000 (33%)]\tLoss: 2.306350\n",
      "Training Epoch: 0 [20480/60000 (34%)]\tLoss: 2.313056\n",
      "Training Epoch: 0 [21120/60000 (35%)]\tLoss: 2.324877\n",
      "Training Epoch: 0 [21760/60000 (36%)]\tLoss: 2.290872\n",
      "Training Epoch: 0 [22400/60000 (37%)]\tLoss: 2.296858\n",
      "Training Epoch: 0 [23040/60000 (38%)]\tLoss: 2.311030\n",
      "Training Epoch: 0 [23680/60000 (39%)]\tLoss: 2.306548\n",
      "Training Epoch: 0 [24320/60000 (41%)]\tLoss: 2.291703\n",
      "Training Epoch: 0 [24960/60000 (42%)]\tLoss: 2.303220\n",
      "Training Epoch: 0 [25600/60000 (43%)]\tLoss: 2.302751\n",
      "Training Epoch: 0 [26240/60000 (44%)]\tLoss: 2.306622\n",
      "Training Epoch: 0 [26880/60000 (45%)]\tLoss: 2.308160\n",
      "Training Epoch: 0 [27520/60000 (46%)]\tLoss: 2.312046\n",
      "Training Epoch: 0 [28160/60000 (47%)]\tLoss: 2.296946\n",
      "Training Epoch: 0 [28800/60000 (48%)]\tLoss: 2.307278\n",
      "Training Epoch: 0 [29440/60000 (49%)]\tLoss: 2.295221\n",
      "Training Epoch: 0 [30080/60000 (50%)]\tLoss: 2.299992\n",
      "Training Epoch: 0 [30720/60000 (51%)]\tLoss: 2.304886\n",
      "Training Epoch: 0 [31360/60000 (52%)]\tLoss: 2.296125\n",
      "Training Epoch: 0 [32000/60000 (53%)]\tLoss: 2.298783\n",
      "Training Epoch: 0 [32640/60000 (54%)]\tLoss: 2.301342\n",
      "Training Epoch: 0 [33280/60000 (55%)]\tLoss: 2.296142\n",
      "Training Epoch: 0 [33920/60000 (57%)]\tLoss: 2.297481\n",
      "Training Epoch: 0 [34560/60000 (58%)]\tLoss: 2.300125\n",
      "Training Epoch: 0 [35200/60000 (59%)]\tLoss: 2.287590\n",
      "Training Epoch: 0 [35840/60000 (60%)]\tLoss: 2.309487\n",
      "Training Epoch: 0 [36480/60000 (61%)]\tLoss: 2.298482\n",
      "Training Epoch: 0 [37120/60000 (62%)]\tLoss: 2.289503\n",
      "Training Epoch: 0 [37760/60000 (63%)]\tLoss: 2.304790\n",
      "Training Epoch: 0 [38400/60000 (64%)]\tLoss: 2.289801\n",
      "Training Epoch: 0 [39040/60000 (65%)]\tLoss: 2.292452\n",
      "Training Epoch: 0 [39680/60000 (66%)]\tLoss: 2.302444\n",
      "Training Epoch: 0 [40320/60000 (67%)]\tLoss: 2.300382\n",
      "Training Epoch: 0 [40960/60000 (68%)]\tLoss: 2.321337\n",
      "Training Epoch: 0 [41600/60000 (69%)]\tLoss: 2.302300\n",
      "Training Epoch: 0 [42240/60000 (70%)]\tLoss: 2.287869\n",
      "Training Epoch: 0 [42880/60000 (71%)]\tLoss: 2.302805\n",
      "Training Epoch: 0 [43520/60000 (72%)]\tLoss: 2.304047\n",
      "Training Epoch: 0 [44160/60000 (74%)]\tLoss: 2.292847\n",
      "Training Epoch: 0 [44800/60000 (75%)]\tLoss: 2.305849\n",
      "Training Epoch: 0 [45440/60000 (76%)]\tLoss: 2.288245\n",
      "Training Epoch: 0 [46080/60000 (77%)]\tLoss: 2.293062\n",
      "Training Epoch: 0 [46720/60000 (78%)]\tLoss: 2.295390\n",
      "Training Epoch: 0 [47360/60000 (79%)]\tLoss: 2.294033\n",
      "Training Epoch: 0 [48000/60000 (80%)]\tLoss: 2.307529\n",
      "Training Epoch: 0 [48640/60000 (81%)]\tLoss: 2.320954\n",
      "Training Epoch: 0 [49280/60000 (82%)]\tLoss: 2.300054\n",
      "Training Epoch: 0 [49920/60000 (83%)]\tLoss: 2.309705\n",
      "Training Epoch: 0 [50560/60000 (84%)]\tLoss: 2.300802\n",
      "Training Epoch: 0 [51200/60000 (85%)]\tLoss: 2.299802\n",
      "Training Epoch: 0 [51840/60000 (86%)]\tLoss: 2.289771\n",
      "Training Epoch: 0 [52480/60000 (87%)]\tLoss: 2.305528\n",
      "Training Epoch: 0 [53120/60000 (88%)]\tLoss: 2.303520\n",
      "Training Epoch: 0 [53760/60000 (90%)]\tLoss: 2.301080\n",
      "Training Epoch: 0 [54400/60000 (91%)]\tLoss: 2.311614\n",
      "Training Epoch: 0 [55040/60000 (92%)]\tLoss: 2.306931\n",
      "Training Epoch: 0 [55680/60000 (93%)]\tLoss: 2.288404\n",
      "Training Epoch: 0 [56320/60000 (94%)]\tLoss: 2.311143\n",
      "Training Epoch: 0 [56960/60000 (95%)]\tLoss: 2.305965\n",
      "Training Epoch: 0 [57600/60000 (96%)]\tLoss: 2.294740\n",
      "Training Epoch: 0 [58240/60000 (97%)]\tLoss: 2.308726\n",
      "Training Epoch: 0 [58880/60000 (98%)]\tLoss: 2.293747\n",
      "Training Epoch: 0 [59520/60000 (99%)]\tLoss: 2.307963\n",
      "Total training loss for epoch : 0 loss: 2.3014306900089485 accuracy: 11.236666666666666\n",
      "Training Epoch: 1 [0/60000 (0%)]\tLoss: 2.310397\n",
      "Training Epoch: 1 [640/60000 (1%)]\tLoss: 2.296221\n",
      "Training Epoch: 1 [1280/60000 (2%)]\tLoss: 2.301882\n",
      "Training Epoch: 1 [1920/60000 (3%)]\tLoss: 2.297734\n",
      "Training Epoch: 1 [2560/60000 (4%)]\tLoss: 2.303436\n",
      "Training Epoch: 1 [3200/60000 (5%)]\tLoss: 2.296114\n",
      "Training Epoch: 1 [3840/60000 (6%)]\tLoss: 2.308820\n",
      "Training Epoch: 1 [4480/60000 (7%)]\tLoss: 2.300340\n",
      "Training Epoch: 1 [5120/60000 (9%)]\tLoss: 2.298418\n",
      "Training Epoch: 1 [5760/60000 (10%)]\tLoss: 2.300146\n",
      "Training Epoch: 1 [6400/60000 (11%)]\tLoss: 2.292653\n",
      "Training Epoch: 1 [7040/60000 (12%)]\tLoss: 2.299822\n",
      "Training Epoch: 1 [7680/60000 (13%)]\tLoss: 2.306644\n",
      "Training Epoch: 1 [8320/60000 (14%)]\tLoss: 2.299060\n",
      "Training Epoch: 1 [8960/60000 (15%)]\tLoss: 2.302597\n",
      "Training Epoch: 1 [9600/60000 (16%)]\tLoss: 2.295895\n",
      "Training Epoch: 1 [10240/60000 (17%)]\tLoss: 2.308539\n",
      "Training Epoch: 1 [10880/60000 (18%)]\tLoss: 2.309983\n",
      "Training Epoch: 1 [11520/60000 (19%)]\tLoss: 2.304655\n",
      "Training Epoch: 1 [12160/60000 (20%)]\tLoss: 2.310166\n",
      "Training Epoch: 1 [12800/60000 (21%)]\tLoss: 2.311437\n",
      "Training Epoch: 1 [13440/60000 (22%)]\tLoss: 2.308382\n",
      "Training Epoch: 1 [14080/60000 (23%)]\tLoss: 2.296613\n",
      "Training Epoch: 1 [14720/60000 (25%)]\tLoss: 2.291392\n",
      "Training Epoch: 1 [15360/60000 (26%)]\tLoss: 2.290643\n",
      "Training Epoch: 1 [16000/60000 (27%)]\tLoss: 2.302972\n",
      "Training Epoch: 1 [16640/60000 (28%)]\tLoss: 2.302269\n",
      "Training Epoch: 1 [17280/60000 (29%)]\tLoss: 2.302139\n",
      "Training Epoch: 1 [17920/60000 (30%)]\tLoss: 2.304119\n",
      "Training Epoch: 1 [18560/60000 (31%)]\tLoss: 2.299172\n",
      "Training Epoch: 1 [19200/60000 (32%)]\tLoss: 2.301112\n",
      "Training Epoch: 1 [19840/60000 (33%)]\tLoss: 2.304195\n",
      "Training Epoch: 1 [20480/60000 (34%)]\tLoss: 2.301265\n",
      "Training Epoch: 1 [21120/60000 (35%)]\tLoss: 2.288963\n",
      "Training Epoch: 1 [21760/60000 (36%)]\tLoss: 2.292635\n",
      "Training Epoch: 1 [22400/60000 (37%)]\tLoss: 2.309728\n",
      "Training Epoch: 1 [23040/60000 (38%)]\tLoss: 2.297816\n",
      "Training Epoch: 1 [23680/60000 (39%)]\tLoss: 2.291670\n",
      "Training Epoch: 1 [24320/60000 (41%)]\tLoss: 2.307405\n",
      "Training Epoch: 1 [24960/60000 (42%)]\tLoss: 2.297811\n",
      "Training Epoch: 1 [25600/60000 (43%)]\tLoss: 2.296777\n",
      "Training Epoch: 1 [26240/60000 (44%)]\tLoss: 2.298079\n",
      "Training Epoch: 1 [26880/60000 (45%)]\tLoss: 2.296240\n",
      "Training Epoch: 1 [27520/60000 (46%)]\tLoss: 2.294610\n",
      "Training Epoch: 1 [28160/60000 (47%)]\tLoss: 2.291525\n",
      "Training Epoch: 1 [28800/60000 (48%)]\tLoss: 2.289600\n",
      "Training Epoch: 1 [29440/60000 (49%)]\tLoss: 2.296263\n",
      "Training Epoch: 1 [30080/60000 (50%)]\tLoss: 2.285760\n",
      "Training Epoch: 1 [30720/60000 (51%)]\tLoss: 2.305245\n",
      "Training Epoch: 1 [31360/60000 (52%)]\tLoss: 2.301501\n",
      "Training Epoch: 1 [32000/60000 (53%)]\tLoss: 2.299929\n",
      "Training Epoch: 1 [32640/60000 (54%)]\tLoss: 2.289165\n",
      "Training Epoch: 1 [33280/60000 (55%)]\tLoss: 2.306356\n",
      "Training Epoch: 1 [33920/60000 (57%)]\tLoss: 2.296931\n",
      "Training Epoch: 1 [34560/60000 (58%)]\tLoss: 2.309536\n",
      "Training Epoch: 1 [35200/60000 (59%)]\tLoss: 2.309640\n",
      "Training Epoch: 1 [35840/60000 (60%)]\tLoss: 2.303902\n",
      "Training Epoch: 1 [36480/60000 (61%)]\tLoss: 2.282402\n",
      "Training Epoch: 1 [37120/60000 (62%)]\tLoss: 2.313873\n",
      "Training Epoch: 1 [37760/60000 (63%)]\tLoss: 2.312781\n",
      "Training Epoch: 1 [38400/60000 (64%)]\tLoss: 2.299445\n",
      "Training Epoch: 1 [39040/60000 (65%)]\tLoss: 2.311834\n",
      "Training Epoch: 1 [39680/60000 (66%)]\tLoss: 2.286682\n",
      "Training Epoch: 1 [40320/60000 (67%)]\tLoss: 2.296367\n",
      "Training Epoch: 1 [40960/60000 (68%)]\tLoss: 2.297951\n",
      "Training Epoch: 1 [41600/60000 (69%)]\tLoss: 2.308769\n",
      "Training Epoch: 1 [42240/60000 (70%)]\tLoss: 2.311723\n",
      "Training Epoch: 1 [42880/60000 (71%)]\tLoss: 2.303425\n",
      "Training Epoch: 1 [43520/60000 (72%)]\tLoss: 2.318732\n",
      "Training Epoch: 1 [44160/60000 (74%)]\tLoss: 2.305448\n",
      "Training Epoch: 1 [44800/60000 (75%)]\tLoss: 2.298560\n",
      "Training Epoch: 1 [45440/60000 (76%)]\tLoss: 2.295788\n",
      "Training Epoch: 1 [46080/60000 (77%)]\tLoss: 2.292752\n",
      "Training Epoch: 1 [46720/60000 (78%)]\tLoss: 2.303056\n",
      "Training Epoch: 1 [47360/60000 (79%)]\tLoss: 2.302706\n",
      "Training Epoch: 1 [48000/60000 (80%)]\tLoss: 2.299582\n",
      "Training Epoch: 1 [48640/60000 (81%)]\tLoss: 2.301582\n",
      "Training Epoch: 1 [49280/60000 (82%)]\tLoss: 2.310978\n",
      "Training Epoch: 1 [49920/60000 (83%)]\tLoss: 2.297570\n",
      "Training Epoch: 1 [50560/60000 (84%)]\tLoss: 2.297362\n",
      "Training Epoch: 1 [51200/60000 (85%)]\tLoss: 2.299292\n",
      "Training Epoch: 1 [51840/60000 (86%)]\tLoss: 2.310791\n",
      "Training Epoch: 1 [52480/60000 (87%)]\tLoss: 2.311448\n",
      "Training Epoch: 1 [53120/60000 (88%)]\tLoss: 2.298482\n",
      "Training Epoch: 1 [53760/60000 (90%)]\tLoss: 2.304119\n",
      "Training Epoch: 1 [54400/60000 (91%)]\tLoss: 2.298665\n",
      "Training Epoch: 1 [55040/60000 (92%)]\tLoss: 2.306407\n",
      "Training Epoch: 1 [55680/60000 (93%)]\tLoss: 2.309755\n",
      "Training Epoch: 1 [56320/60000 (94%)]\tLoss: 2.302380\n",
      "Training Epoch: 1 [56960/60000 (95%)]\tLoss: 2.310998\n",
      "Training Epoch: 1 [57600/60000 (96%)]\tLoss: 2.300955\n",
      "Training Epoch: 1 [58240/60000 (97%)]\tLoss: 2.294276\n",
      "Training Epoch: 1 [58880/60000 (98%)]\tLoss: 2.298219\n",
      "Training Epoch: 1 [59520/60000 (99%)]\tLoss: 2.299830\n",
      "Total training loss for epoch : 1 loss: 2.301428302264671 accuracy: 11.205\n",
      "Training Epoch: 2 [0/60000 (0%)]\tLoss: 2.303299\n",
      "Training Epoch: 2 [640/60000 (1%)]\tLoss: 2.314483\n",
      "Training Epoch: 2 [1280/60000 (2%)]\tLoss: 2.303081\n",
      "Training Epoch: 2 [1920/60000 (3%)]\tLoss: 2.309985\n",
      "Training Epoch: 2 [2560/60000 (4%)]\tLoss: 2.297933\n",
      "Training Epoch: 2 [3200/60000 (5%)]\tLoss: 2.306927\n",
      "Training Epoch: 2 [3840/60000 (6%)]\tLoss: 2.294143\n",
      "Training Epoch: 2 [4480/60000 (7%)]\tLoss: 2.299011\n",
      "Training Epoch: 2 [5120/60000 (9%)]\tLoss: 2.300499\n",
      "Training Epoch: 2 [5760/60000 (10%)]\tLoss: 2.291521\n",
      "Training Epoch: 2 [6400/60000 (11%)]\tLoss: 2.296452\n",
      "Training Epoch: 2 [7040/60000 (12%)]\tLoss: 2.300978\n",
      "Training Epoch: 2 [7680/60000 (13%)]\tLoss: 2.305824\n",
      "Training Epoch: 2 [8320/60000 (14%)]\tLoss: 2.303712\n",
      "Training Epoch: 2 [8960/60000 (15%)]\tLoss: 2.292829\n",
      "Training Epoch: 2 [9600/60000 (16%)]\tLoss: 2.293904\n",
      "Training Epoch: 2 [10240/60000 (17%)]\tLoss: 2.303760\n",
      "Training Epoch: 2 [10880/60000 (18%)]\tLoss: 2.291186\n",
      "Training Epoch: 2 [11520/60000 (19%)]\tLoss: 2.297532\n",
      "Training Epoch: 2 [12160/60000 (20%)]\tLoss: 2.284010\n",
      "Training Epoch: 2 [12800/60000 (21%)]\tLoss: 2.314668\n",
      "Training Epoch: 2 [13440/60000 (22%)]\tLoss: 2.303592\n",
      "Training Epoch: 2 [14080/60000 (23%)]\tLoss: 2.305249\n",
      "Training Epoch: 2 [14720/60000 (25%)]\tLoss: 2.303226\n",
      "Training Epoch: 2 [15360/60000 (26%)]\tLoss: 2.306234\n",
      "Training Epoch: 2 [16000/60000 (27%)]\tLoss: 2.298168\n",
      "Training Epoch: 2 [16640/60000 (28%)]\tLoss: 2.309000\n",
      "Training Epoch: 2 [17280/60000 (29%)]\tLoss: 2.309963\n",
      "Training Epoch: 2 [17920/60000 (30%)]\tLoss: 2.304938\n",
      "Training Epoch: 2 [18560/60000 (31%)]\tLoss: 2.309158\n",
      "Training Epoch: 2 [19200/60000 (32%)]\tLoss: 2.299763\n",
      "Training Epoch: 2 [19840/60000 (33%)]\tLoss: 2.297643\n",
      "Training Epoch: 2 [20480/60000 (34%)]\tLoss: 2.312345\n",
      "Training Epoch: 2 [21120/60000 (35%)]\tLoss: 2.316071\n",
      "Training Epoch: 2 [21760/60000 (36%)]\tLoss: 2.294729\n",
      "Training Epoch: 2 [22400/60000 (37%)]\tLoss: 2.296542\n",
      "Training Epoch: 2 [23040/60000 (38%)]\tLoss: 2.297056\n",
      "Training Epoch: 2 [23680/60000 (39%)]\tLoss: 2.300874\n",
      "Training Epoch: 2 [24320/60000 (41%)]\tLoss: 2.298722\n",
      "Training Epoch: 2 [24960/60000 (42%)]\tLoss: 2.303184\n",
      "Training Epoch: 2 [25600/60000 (43%)]\tLoss: 2.295532\n",
      "Training Epoch: 2 [26240/60000 (44%)]\tLoss: 2.312183\n",
      "Training Epoch: 2 [26880/60000 (45%)]\tLoss: 2.294905\n",
      "Training Epoch: 2 [27520/60000 (46%)]\tLoss: 2.296449\n",
      "Training Epoch: 2 [28160/60000 (47%)]\tLoss: 2.303520\n",
      "Training Epoch: 2 [28800/60000 (48%)]\tLoss: 2.302202\n",
      "Training Epoch: 2 [29440/60000 (49%)]\tLoss: 2.316398\n",
      "Training Epoch: 2 [30080/60000 (50%)]\tLoss: 2.300432\n",
      "Training Epoch: 2 [30720/60000 (51%)]\tLoss: 2.303279\n",
      "Training Epoch: 2 [31360/60000 (52%)]\tLoss: 2.301116\n",
      "Training Epoch: 2 [32000/60000 (53%)]\tLoss: 2.305638\n",
      "Training Epoch: 2 [32640/60000 (54%)]\tLoss: 2.308819\n",
      "Training Epoch: 2 [33280/60000 (55%)]\tLoss: 2.310318\n",
      "Training Epoch: 2 [33920/60000 (57%)]\tLoss: 2.309465\n",
      "Training Epoch: 2 [34560/60000 (58%)]\tLoss: 2.296445\n",
      "Training Epoch: 2 [35200/60000 (59%)]\tLoss: 2.301581\n",
      "Training Epoch: 2 [35840/60000 (60%)]\tLoss: 2.303585\n",
      "Training Epoch: 2 [36480/60000 (61%)]\tLoss: 2.314105\n",
      "Training Epoch: 2 [37120/60000 (62%)]\tLoss: 2.304976\n",
      "Training Epoch: 2 [37760/60000 (63%)]\tLoss: 2.316527\n",
      "Training Epoch: 2 [38400/60000 (64%)]\tLoss: 2.302690\n",
      "Training Epoch: 2 [39040/60000 (65%)]\tLoss: 2.304089\n",
      "Training Epoch: 2 [39680/60000 (66%)]\tLoss: 2.304062\n",
      "Training Epoch: 2 [40320/60000 (67%)]\tLoss: 2.290270\n",
      "Training Epoch: 2 [40960/60000 (68%)]\tLoss: 2.304502\n",
      "Training Epoch: 2 [41600/60000 (69%)]\tLoss: 2.301956\n",
      "Training Epoch: 2 [42240/60000 (70%)]\tLoss: 2.299219\n",
      "Training Epoch: 2 [42880/60000 (71%)]\tLoss: 2.303083\n",
      "Training Epoch: 2 [43520/60000 (72%)]\tLoss: 2.307253\n",
      "Training Epoch: 2 [44160/60000 (74%)]\tLoss: 2.300303\n",
      "Training Epoch: 2 [44800/60000 (75%)]\tLoss: 2.300095\n",
      "Training Epoch: 2 [45440/60000 (76%)]\tLoss: 2.302757\n",
      "Training Epoch: 2 [46080/60000 (77%)]\tLoss: 2.314115\n",
      "Training Epoch: 2 [46720/60000 (78%)]\tLoss: 2.296272\n",
      "Training Epoch: 2 [47360/60000 (79%)]\tLoss: 2.303243\n",
      "Training Epoch: 2 [48000/60000 (80%)]\tLoss: 2.299235\n",
      "Training Epoch: 2 [48640/60000 (81%)]\tLoss: 2.300511\n",
      "Training Epoch: 2 [49280/60000 (82%)]\tLoss: 2.307416\n",
      "Training Epoch: 2 [49920/60000 (83%)]\tLoss: 2.294349\n",
      "Training Epoch: 2 [50560/60000 (84%)]\tLoss: 2.308439\n",
      "Training Epoch: 2 [51200/60000 (85%)]\tLoss: 2.290556\n",
      "Training Epoch: 2 [51840/60000 (86%)]\tLoss: 2.307140\n",
      "Training Epoch: 2 [52480/60000 (87%)]\tLoss: 2.303160\n",
      "Training Epoch: 2 [53120/60000 (88%)]\tLoss: 2.306548\n",
      "Training Epoch: 2 [53760/60000 (90%)]\tLoss: 2.295855\n",
      "Training Epoch: 2 [54400/60000 (91%)]\tLoss: 2.293033\n",
      "Training Epoch: 2 [55040/60000 (92%)]\tLoss: 2.308563\n",
      "Training Epoch: 2 [55680/60000 (93%)]\tLoss: 2.300643\n",
      "Training Epoch: 2 [56320/60000 (94%)]\tLoss: 2.311443\n",
      "Training Epoch: 2 [56960/60000 (95%)]\tLoss: 2.295767\n",
      "Training Epoch: 2 [57600/60000 (96%)]\tLoss: 2.291975\n",
      "Training Epoch: 2 [58240/60000 (97%)]\tLoss: 2.297950\n",
      "Training Epoch: 2 [58880/60000 (98%)]\tLoss: 2.299966\n",
      "Training Epoch: 2 [59520/60000 (99%)]\tLoss: 2.308513\n",
      "Total training loss for epoch : 2 loss: 2.3013863294109353 accuracy: 11.151666666666667\n",
      "Total training loss across epochs : 3 loss: 2.3014151072281845 accuracy: 11.197777777777778\n",
      "Testing Loss: 2.301 | Accuracy: 11.237\n"
     ]
    }
   ],
   "source": [
    "initializeModel(0.01, True, True, 32)\n",
    "\n",
    "trainlosses = []\n",
    "traincounter = []\n",
    "testlosses = []\n",
    "\n",
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 10: Show Model Performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0, 0.5, 'loss')"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(traincounter, trainlosses, color='green')\n",
    "plt.scatter(testcounter, testlosses, color='red')\n",
    "plt.legend(['Training Loss', 'Testing Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 11: Show prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 6 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  output = cnn(exampledata)\n",
    "\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(exampledata[i][0], cmap='Blues', interpolation='none')\n",
    "  plt.title(\"Prediction: {}\".format(\n",
    "    output.data.max(1, keepdim=True)[1][i].item()))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
